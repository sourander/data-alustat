{"config":{"lang":["fi"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tervetuloa kurssille","text":"<p>Oppimateriaali on tarkoitettu Kajaanin Ammattikorkeakoulun toisen vuoden IT-alan opiskelijoille. Materiaalin ymm\u00e4rt\u00e4misess\u00e4 on eduksi, ett\u00e4 ymm\u00e4rt\u00e4\u00e4 SQL perusteet, tietokantojen perusteet sek\u00e4 osaa Pythonia v\u00e4hint\u00e4\u00e4n perusteiden verran. Materiaali on pyritty kirjoittamaan siten, ettei se ole lukossa yhden toimittajan (eng. vendor) ratkaisuun tai palveluun, vaan pikemminkin selitt\u00e4\u00e4 arkkitehtuureja, joita voi toteuttaa useissa eri ymp\u00e4rit\u00f6iss\u00e4 - mukaan lukien lokaalilla tietokoneella.</p>"},{"location":"#faktavirheet","title":"Faktavirheet","text":"<p>Mik\u00e4li oppimateriaali sis\u00e4lt\u00e4\u00e4 virheellist\u00e4 tietoa, tee jompi kumpi:</p> <ul> <li>Forkkaa GitHubin repository ja tarjoa Pull Request, joka sis\u00e4lt\u00e4\u00e4 korjausehdotukset.</li> <li>Ota yhteytt\u00e4 yll\u00e4pitoon ja esittele virheellisen tiedon korjaus.</li> </ul>"},{"location":"data_alustat/arkkitehtuurit/","title":"Arkkitehtuurit","text":"<p>On t\u00e4rke\u00e4\u00e4 muistaa, ett\u00e4 data-alusta ei ole yksitt\u00e4inen tuote vaan kollaasi eri ty\u00f6kaluja. Loppuk\u00e4ytt\u00e4j\u00e4n n\u00e4k\u00f6kulmasta alusta voi olla \"se mei\u00e4n firman power bi\", mutta todellisuudessa kokonaisuus koostuu useista eri ty\u00f6kaluista. Lis\u00e4ksi eri yritysten data-alustat voivat olla kesken\u00e4\u00e4n hyvin erilaisia. Yrityksell\u00e4 voi olla yksi monoliittinen, keskitetty tietoalusta, tai hyvinkin hajautettu data-alustojen patteristo.</p>"},{"location":"data_alustat/arkkitehtuurit/#yleisnakyma","title":"Yleisn\u00e4kym\u00e4","text":""},{"location":"data_alustat/arkkitehtuurit/#50000-jalan-nakyma","title":"50,000 jalan n\u00e4kym\u00e4","text":"<p>Kuvio 1: Karkea 50,000 jalan n\u00e4kym\u00e4 data-alustan arkkitehtuuriin.</p> <p>Yll\u00e4 olevan graafin (Kuvio 1) komponentit ovat vasemmalta lukien:</p> <ul> <li>Sininen: L\u00e4hdej\u00e4rjestelm\u00e4t (source system)<ul> <li>Datan alkuper\u00e4iset l\u00e4hteet, kuten operatiiviset tietokannat.</li> </ul> </li> <li>Hopea: Sis\u00e4\u00e4ntuonnin ty\u00f6kalut (ingestion tools)<ul> <li>Kerros, joka louhii tai vastaanottaa datan tietoalustaan.</li> </ul> </li> <li>Oranssi: Toistaiseksi mustana laatikkona n\u00e4hty kokonaisuus, joka sis\u00e4lt\u00e4\u00e4 tallennuksen ja laskennan (eng. storage &amp; compute.)</li> <li>Violetti: Datan tarjoilukerros (eng. serving layer) on loppuk\u00e4ytt\u00e4j\u00e4n n\u00e4kym\u00e4 dataan. Tyypillinen esimerkki on BI-ty\u00f6kalu kuten Power BI, Qlik tai Tableau, mutta kyseess\u00e4 voi hyvin olla my\u00f6s k\u00e4ytt\u00f6tarpeeseen r\u00e4\u00e4t\u00e4l\u00f6ity verkkosivusto (esim. Plotly, JavaScript D3, React) tai suoraa kantayhteytt\u00e4 muistuttava connector (esim. ODBC connector). Tietoalusta voi my\u00f6s puskea dataa ulos, jolloin sit\u00e4 ei ylip\u00e4\u00e4t\u00e4ns\u00e4 noudeta, vaan se sy\u00f6tet\u00e4\u00e4n j\u00e4rjestelm\u00e4\u00e4n X.</li> <li>Ihmisfiguuri: Tietoalustan loppuk\u00e4ytt\u00e4j\u00e4. Heid\u00e4n tarpeitaan varten koko alusta luodaan. Loppuk\u00e4ytt\u00e4ji\u00e4 voi olla useita erilaisia, kuten myynti, ylin johto, tutkimus ja tuotekehitys, ohjelmistonkehitt\u00e4j\u00e4t, tietoturva-asiantuntijat, ja niin edelleen.</li> </ul>"},{"location":"data_alustat/arkkitehtuurit/#30000-jalan-nakyma","title":"30,000 jalan n\u00e4kym\u00e4","text":"<p>Kuvio 2: Edellist\u00e4 kuviota yksityiskohtaisempi 30,000 jalan n\u00e4kym\u00e4 data-alustan arkkitehtuuriin.</p> <p>Huomaathan, ett\u00e4 yll\u00e4 olevassa Kuvio 2:ssa on jo valittu tiettyj\u00e4 palveluita esimerkeiksi. Data-alustan ei ole pakko k\u00e4ytt\u00e4\u00e4 medaljonkiarkkitehtuuria (bronze, silver, gold) eik\u00e4 mit\u00e4\u00e4n muutakaan yksitt\u00e4ist\u00e4 valittua tuotetta. Ty\u00f6kalut ovat esill\u00e4 liiallisen abstraktion v\u00e4lttelemiseksi.</p>"},{"location":"data_alustat/arkkitehtuurit/#datan-maara","title":"Datan m\u00e4\u00e4r\u00e4","text":""},{"location":"data_alustat/arkkitehtuurit/#anti-big-data-duckdb","title":"Anti Big Data: DuckDB","text":"<p>Kaikki eiv\u00e4t niele t\u00e4ysin purematta big datan tarpeellisuutta kaikissa maailman yrityksiss\u00e4. T\u00e4st\u00e4 esimerkkin\u00e4 on yhden noden kolumnaarinen OLAP-engine nimelt\u00e4\u00e4n DuckDB. DuckDB ei ole perinteinen tietokantapalvelin vaan in-process tietokanta. Tietokanta voi olla tiedostossa (esim. <code>db.duckdb</code>) tai k\u00e4yt\u00f6ss\u00e4 voi olla DuckLake, jolloin kannan metadata on katalogitiedostossa (tai tietokannassa) ja data tallennetaan tiedostoina (esim. Parquet) tiedostoj\u00e4rjestelm\u00e4\u00e4n tai pilveen.</p> <p>Huomaa, ett\u00e4 50,000 jalan p\u00e4\u00e4st\u00e4 katseltuna kaikki arkkitehtuurit n\u00e4ytt\u00e4v\u00e4t yll\u00e4tt\u00e4v\u00e4n samalta. Periaatteessa DuckDB:n arkkitehtuuri on my\u00f6s v\u00e4h\u00e4n l\u00e4hemp\u00e4\u00e4in katsottuna yll\u00e4tt\u00e4v\u00e4n samanlainen kuin modernien tietoalustojen \"big data\"-versionsa. Yll\u00e4 esitelty 30,000 jalan n\u00e4kym\u00e4 on hyvinkin toteutettavissa DuckDB:n avulla.</p> <p>Teht\u00e4v\u00e4</p> <p>Lue MotherDuckin Jordan Tiganin kirjoitus Big Data is Dead. Mihin Jordan perustaa v\u00e4itteens\u00e4?</p> <p>Tip</p> <p>DuckDB on oikeasti olemassa oleva projekti, joka on julkaistu avoimen l\u00e4hdekoodin lisenssill\u00e4. DuckDB on SQL-tietokanta, joka on suunniteltu toimimaan yhdell\u00e4 tietokoneella. DuckDB on my\u00f6s yksi esimerkki siit\u00e4, ett\u00e4 data-alustan ei tarvitse olla monoliittinen, vaan se voi koostua useista eri ty\u00f6kaluista.</p> <p>Alla esimerkki DuckDB-tyylisest\u00e4 alusta, jossa kaikki data mahtuu yhden tietokoneen rammiin v\u00e4hint\u00e4\u00e4n paloiteltuna. Huomaa, ett\u00e4 arkkitehtuuri ei loogisella tasolla eroa kovinkaan paljon esimerkiksi yll\u00e4 olevasta 30,000 jalan n\u00e4kym\u00e4st\u00e4, vaikka fyysisell\u00e4 tasolla ero onkin merkitt\u00e4v\u00e4mpi (yksi tietokone vs. monta hajautetun laskennan klusteria.) Kuvan alusta on jotakin, mik\u00e4 on t\u00e4ysin teht\u00e4viss\u00e4 3 opintopisteen kurssin aikana.</p> <p></p> <p>Kuvio 3: Yhden koneen ja yhden tietol\u00e4hteen data-alusta. Alustaa on helppo jatkaa suuremmaksi. Siihen voi tuoda uusia tietol\u00e4hteit\u00e4, siirt\u00e4\u00e4 laskennan pilveen, siirt\u00e4\u00e4 tallennuksen pilveen, vaihtaa BI-ty\u00f6kalun, ottaa orkestrointiin dbt Cloudin ja/tai Airflow:n. Oikein k\u00e4ytettyn\u00e4 alustasta voisi olla hyvinkin realistista bisneshy\u00f6ty\u00e4.</p> <p>Teht\u00e4v\u00e4</p> <p>Vertaa yll\u00e4 esitelty\u00e4 alustaa Christophe Blefarin Fancy Data Stackiin. Kuinka paljon yht\u00e4l\u00e4isyyksi\u00e4 ja eroja l\u00f6yd\u00e4t?</p>"},{"location":"data_alustat/arkkitehtuurit/#pro-big-data-muut","title":"Pro Big Data: Muut","text":"<p>Mik\u00e4li voidaan olettaa, ett\u00e4 dataa on paljon, ja ett\u00e4 dataa on useista eri l\u00e4hteist\u00e4, on todenn\u00e4k\u00f6ist\u00e4, ett\u00e4 dataa ei voida tallentaa yhdelle koneelle (esim. <code>db.duckdb</code>-tiedostoon). Vaikka data hajautettaisiin pilvipalvelun tarjoamaan loputtamasti skaalautuvaan tallennustilaan eri tiedostoihin partitioituina, sen prosessointi yhdell\u00e4 koneella ei v\u00e4ltt\u00e4m\u00e4tt\u00e4 ole realistista. T\u00e4ll\u00f6in tarvitaan hajautettua laskentaa. Hajautettu laskenta k\u00e4sitell\u00e4\u00e4n Kerrokset/Processor-osiossa.</p> <p>Big data -tyyliset modernit tietoalustat ovat siis, kuten aiemmin todettua, 50,000 ja 30,000 jalan et\u00e4isyydelt\u00e4 katsottuna loogisesti hyvinkin samanlaisia kuin sinun tietokoneeseesi viritelty DuckDB, jossa kaikki kerrokset (tietojen lataus, mallinnus ja esitys) py\u00f6riv\u00e4t yhden tietokoneen muistissa. Yhden tietokoneen ty\u00f6kalut kuten Pythonin Pandas-kirjasto, perinteinen Jupyter Notebook sek\u00e4 DuckDB eiv\u00e4t edusta hajautetun laskennan ty\u00f6kaluja, joten ne menev\u00e4t vaihtoon big dataa k\u00e4sitelless\u00e4. Yritys voi valita ainakin seuraavista vaihtoehdoista:</p> <ul> <li>Hallittuja, suljetun l\u00e4hdekoodin pilvipalveluita<ul> <li>Hyperscalereiden (AWS, Azure, GCP) omat ratkaisut </li> <li>Muut SaaS-tarjoajat (Snowflake, Fivetran)</li> </ul> </li> <li>Hallittuja, avointa l\u00e4hdekoodia olevia pilvipalveluita<ul> <li>Hyperscalereiden avoimen l\u00e4hdekoodin versiot (esim. AWS MSK = Apache Kafka)</li> <li>Muut SaaS-tarjoajat (esim. Confluent = Apache Kafka, Databricks = Apache Spark)</li> </ul> </li> <li>Itse hostattuja avoimen l\u00e4hdekoodin palveluita<ul> <li>Apache Spark, Kafka etc.</li> </ul> </li> </ul> <p>Yll\u00e4 olevan listan itemit eiv\u00e4t ole toisiaan poissulkevia. On mahdollista ottaa hallittu alusta esimerkiksi tietovarastoksi (esim. Snowflake), mutta koodata tee se itse -periaatteella ohjelmisto, joka kirjoittaa datan tietoalustaan. On my\u00f6s mahdollista koodata koko ratkaisu itse, mit\u00e4 valtavat IT-j\u00e4tit kuten Google ja Netflix tekev\u00e4tkin. J\u00e4tet\u00e4\u00e4n t\u00e4m\u00e4 vaihtoehto kuitenkin k\u00e4sittelem\u00e4tt\u00e4 useimmiten t\u00e4ysin ep\u00e4realistisena.</p>"},{"location":"data_alustat/arkkitehtuurit/#kaytannon-toteutuksia","title":"K\u00e4yt\u00e4nn\u00f6n toteutuksia","text":"<p>Oletetaan, ett\u00e4 Yritys X tarvitsee nimenomaan big dataan kykenev\u00e4n, hajautetun alustan. Alla on pari esimerkki\u00e4, jotka noudattavat aiemmin esiteltyj\u00e4 hallittuja (eng. managed) ja itse hostattuja (eng. self-hosted) vaihtoehtoja. Huomaa, ett\u00e4 itse hostattu voi kuitenkin olla pilvipalvelussa (esim. AWS EC2) tai omassa konesalissa (eli on-premise.)</p>"},{"location":"data_alustat/arkkitehtuurit/#saas","title":"SaaS","text":"<p>Yritykselle itselleen hyvin yksinkertainen ratkaisu on ostaa ratkaisut SaaS (Software as a service) -palveluntarjojilta palveluina. Hintalappu saattaa osoittautua korkeammaksi kuin r\u00e4\u00e4t\u00e4l\u00f6idymmill\u00e4 vaihtoehdoilla, mutta toisaalta ratkaisu on nopea ja helppo ottaa k\u00e4ytt\u00f6\u00f6n. Snowflake hallinnoi AWS/Azure/Google tallennustilan, laskennan ja muun. Data ja laskenta ovat heid\u00e4n pilvitileill\u00e4\u00e4n. Annetut tuotteet ovat esimerkkej\u00e4. Snowflaken voi korvata esimerkiksi Dremio:lla ja Tableaun esimerkiksi Qlik Sense:ll\u00e4 tai Power BI Pro:lla. Fivetran:n voi korvata esimerkiksi Stitch:ll\u00e4. Dbt:n voi korvata esimerkiksi Matillion:lla tai jopa HashiCorp:n Terraform:lla.</p> <p></p> <p>Kuvio 4: SaaS-ratkaisu, jossa kaikki on ostettu palveluna.</p>"},{"location":"data_alustat/arkkitehtuurit/#hadoop-like","title":"Hadoop-like","text":"<p>Hadoop-ekosysteemi on toteutettavissa joko itse hostattuna, Databricksin avulla tai k\u00e4ytt\u00e4en hyperscalereiden tarjoamia vastaavia ratkaisuja. Alla taulukossa muut paitsi Databricks, joka esitell\u00e4\u00e4n alempana.</p> Open Source AWS Fabric (Azure) GCP Ingestion Airbyte AWS Lake Formation, DMS Data Factory (Azure Data Factory) Data Fusion Orchestration Airflow Data Pipeline, MWAA (Airflow) Data Pipeline (Azure Data Factory) Dataproc Streaming Kafka Kinesis, MSK (Kafka) Real-Time Intelligence (Event Hubs) Pub/Sub SQL (Query) Hive Athena, Redshift Data Warehouse (Azure Synapse Analytics) BigQuery Storage HDFS S3 OneLake (Azure Data Lake Storage) Cloud Storage Compute Spark EMR Fabric Data Engineering (Azure Synapse Spark) Dataproc Auth ??? IAM Microsoft Entra ID (Azure Entra ID) Cloud IAM BI Superset QuickSight Power BI (Same in both) Looker <p>Note</p> <p>Taulukon Fabric-sarake edustaa Microsofin uutta, pilvipohjaista data-alustaratkaisua, joka yhdist\u00e4\u00e4 useita eri ty\u00f6kaluja ja palveluita yhteen kokonaisuuteen. Vanhempi vastine on suluissa per\u00e4ss\u00e4. Huomaa, ett\u00e4 aivan 1:1 vastinetta ei aina kaikissa tilanteissa l\u00f6ydy, koska uusi, syntynyt kokonaisuus voi erota entisist\u00e4 ty\u00f6kaluista granulariteetiltaan ja toiminnaltaan. T\u00e4ss\u00e4 mieless\u00e4 Fabric muistuttaa hieman one-stop-shop -ratkaisua, mutta aivan kuten Databricks tai Snowflake, se ei kuitenkaan ole t\u00e4ysin monoliittinen ratkaisu.</p>"},{"location":"data_alustat/arkkitehtuurit/#databricks","title":"Databricks","text":"<p>Databricks on Apache Sparkin luojien perustama yritys, joka myy Apache Sparkia heid\u00e4n hallinnoimana. Databricks ei siis yll\u00e4pid\u00e4 omia palvelimiaa ja vuokraa niit\u00e4 samalla tavalla kuin AWS, Azure tai GCP. P\u00e4invastoin: asiakas antaa Databricksille luvan hallinnoida virtuaalikoneita heid\u00e4n virtuaaliymp\u00e4rist\u00f6ss\u00e4\u00e4n. Asiakkaan rajapinta (esim. <code>asiakas.databricks.com</code>) ja siihen liittyv\u00e4 metadata (kuten ajastetut Jobin) yll\u00e4pidet\u00e4\u00e4n Databricksin hallinnoimalla tilill\u00e4. Sen sijaan asiakkaan data pysyy heid\u00e4n omalla tilill\u00e4\u00e4n. Data ei poistu asiakkaan AWS/Azure/GCP-tililt\u00e4.</p> <p>Teht\u00e4v\u00e4</p> <p>Tutustu siihen, milt\u00e4 Databricks n\u00e4ytt\u00e4\u00e4 k\u00e4yt\u00e4nn\u00f6ss\u00e4. Databricks Web UI sek\u00e4 siihen kuuluva (Jupyter) Notebook interface n\u00e4kyy n\u00e4iss\u00e4 videoissa: How to Build a Cloud Data Platform - Workshop Series. Playlistill\u00e4 on kestoa 4 x 2 tuntia, joten ei ole v\u00e4ltt\u00e4m\u00e4t\u00f6nt\u00e4, ett\u00e4 katsot sen kokonaan. Kelaile, silm\u00e4ile ja tutustu siten, kuten ajank\u00e4ytt\u00f6si sallii. Videolla n\u00e4kyy k\u00e4yt\u00e4nn\u00f6n tasolla useita t\u00e4m\u00e4n kurssin aiheita, joten videon katsominen voi selkeytt\u00e4\u00e4 useita termej\u00e4 merkitt\u00e4v\u00e4ll\u00e4 tavalla. </p> <p>Mik\u00e4li aiot yritykseen t\u00f6ihin, joka k\u00e4ytt\u00e4\u00e4 Databricksi\u00e4 mihink\u00e4\u00e4n, katso koko videosarja kokonaisuudessaan.</p>"},{"location":"data_alustat/arkkitehtuurit/#hyperscalereiden-omat","title":"Hyperscalereiden omat","text":"<p>Hyperscalarit (eli AWS, Azure ja GCP) tarjoavat my\u00f6s omia pilvinatiiveja ratkaisujaan. Huomaa, ett\u00e4 jokaisella alustalla on lopulta hyvin samankaltaisia ty\u00f6kaluja. Esimerkiksi datan visualisointiin on kullakin oma ty\u00f6kalunsa: GCP Looker, AWS QuickSight ja Azure Power BI. </p> <p>Valtaosa t\u00e4m\u00e4n kurssin graafeista on yksinkertaistettuja, Excalidraw:lla piirrettyj\u00e4 diagrammeja. T\u00e4m\u00e4 otsake on ainakin toistaiseksi poikkeus. Voi olla, ett\u00e4 jatkossa palveluntarjoajan graafit korvataan yksinkertaistetuilla, Excalidraw:lla piirretyill\u00e4 graafeilla. Toivon mukaan t\u00e4st\u00e4 huolimatta graafeista on kuitenkin luettavissa, ett\u00e4 palveluntarjoajilla on hyvin samankaltaisia ty\u00f6kaluja ja koko arkkitehtuurit muistuttavat suuresti toisiaan.</p>"},{"location":"data_alustat/arkkitehtuurit/#microsoftazure","title":"Microsoft/Azure","text":"<p>Azure data-alusta-arkkitehtuuri perustuu kerroksittaiseen rakenteeseen, jossa data etenee raakadatasta rikastettuun ja kuratoituun muotoon. Arkkitehtuurissa Azure Synapse Analytics toimii keskeisen\u00e4 komponenttina, joka yhdist\u00e4\u00e4 eri toimintoja kuten datan varastointi (Azure Data Lake Storage), prosessointi (SQL ja Spark pools) ja analytiikka. Microsoft Fabric puolestaan edustaa Microsoftin pyrkimyst\u00e4 yhdist\u00e4\u00e4 aiemmin erillisin\u00e4 toimineet palvelut (mm. Azure Synapse, Power BI, Data Factory) yhten\u00e4isemm\u00e4ksi kokonaisuudeksi \u2013 kenties jopa \"one-stop-shop\"-ratkaisuksi tai kohti monoliittisempaa ratkaisua.</p> <p></p> <p>Kuvio 5: Azure end-to-end (l\u00e4hde)</p> <p></p> <p>Kuvio 6: Microsoft Fabric (l\u00e4hde) on Microsoftin uusi, pilvipohjainen data-alustaratkaisu, joka yhdist\u00e4\u00e4 useita eri ty\u00f6kaluja ja palveluita yhteen kokonaisuuteen.</p>"},{"location":"data_alustat/arkkitehtuurit/#aws","title":"AWS","text":"<p>AWS data-alusta-arkkitehtuuri jakautuu toiminnallisiin kerroksiin: sis\u00e4\u00e4ntuonti (ingestion), tallennus (storage), luettelointi ja haku (cataloging and search), prosessointi (processing), kulutus (consumption) sek\u00e4 tietoturva ja hallinta (security and governance). Arkkitehtuuri hy\u00f6dynt\u00e4\u00e4 palveluna tarjottavia (serverless) komponentteja, kuten Amazon S3 data-j\u00e4rven tallennustilana, AWS Glue ETL-prosesseihin ja metatietojen hallintaan, Lake Formation keskitettyn\u00e4 tietoluettelona ja Amazon Athena SQL-kyselyihin. AWS:n malli perustuu resurssien k\u00e4ytt\u00f6\u00f6n pohjautuvaan laskutukseen, jossa infrastruktuurin skaalautuvuus m\u00e4\u00e4r\u00e4ytyy tarpeen mukaan ilman etuk\u00e4teist\u00e4 kapasiteetin m\u00e4\u00e4rittely\u00e4, toisin kuin Fabric, jossa kapasiteetti on m\u00e4\u00e4ritelt\u00e4v\u00e4 etuk\u00e4teen.</p> <p></p> <p>Kuvio 6: Amazon Web Services end-to-end (l\u00e4hde)</p>"},{"location":"data_alustat/arkkitehtuurit/#gcp","title":"GCP","text":"<p>Google Cloud Platform (GCP) data-alusta-arkkitehtuurissa BigQuery toimii keskeisen\u00e4 palveluna, joka yhdist\u00e4\u00e4 datan varastoinnin ja analytiikan samaan ymp\u00e4rist\u00f6\u00f6n. Arkkitehtuuri koostuu toisiaan t\u00e4ydent\u00e4vist\u00e4 palveluista: Data Fusion (datan ker\u00e4\u00e4minen), Cloud Storage (tallennustila), Dataflow (stream- ja batch-prosessointi), Dataproc (Hadoop/Spark-ymp\u00e4rist\u00f6) ja Looker (visualisointi). GCP:n arkkitehtuuri on suunniteltu tukemaan erityisesti suurten datamassojen analytiikkaa, geospatiaalista analyysi\u00e4 sek\u00e4 integroitumaan Googlen koneoppimispalveluihin.</p> <p></p> <p>Kuvio 7: Google Cloud Platform end-to-end (l\u00e4hde)</p>"},{"location":"data_alustat/historia/","title":"Historia","text":"<p>T\u00e4m\u00e4 materiaali pyrkii esittelem\u00e4\u00e4n yleispiirteitt\u00e4in, mihin k\u00e4ytt\u00f6\u00f6n relaatiotietokannat ja sen kyselykieli SQL on alunperin kehitetty, miksi tietovarastoja tarvitaan t\u00e4ydent\u00e4m\u00e4\u00e4n niihin liittyvi\u00e4 puutteita, ja mik\u00e4 2010 Web 2.0 buumeissa syntynyt tietoj\u00e4rvi on, ja mit\u00e4 n\u00e4in 2024 oikeastaan kuuluu yrityksen \"analytics/data st\u00e4kkiin tai platformiin\".</p>"},{"location":"data_alustat/historia/#transaktiokannat","title":"Transaktiokannat","text":""},{"location":"data_alustat/historia/#sql-synty","title":"SQL synty","text":"<p>Tietokantojen normalisointiprosessin keksi IBM:n tutkija E.F. \u201dTed\u201d Codd 1970-luvun alussa, mink\u00e4 voi n\u00e4hd\u00e4 jossain m\u00e4\u00e4rin nykymuotoisten tietokantojen syntyhetken\u00e4. Codd julkaisi artikkelin nimelt\u00e4 \"A Relational Model of Data for Large Shared Data Banks\", jossa h\u00e4n esitteli relaatiotietokantamallin. T\u00e4m\u00e4 malli perustui joukko-oppiin ja tarjosi tavan j\u00e4rjest\u00e4\u00e4 tietoa taulukoihin, joissa tiedot esitettiin rivein\u00e4 ja sarakkeina. Coddin malli mahdollisti tehokkaan tiedonhallinnan ja -hakemisen, mik\u00e4 oli merkitt\u00e4v\u00e4 parannus aikaisempiin hierarkkisiin ja verkkomalleihin verrattuna. <sup>1</sup></p> <p>Relaatiotietokantamallin perusk\u00e4sitteit\u00e4 ovat relaatiot (eli taulut) ja niiden v\u00e4liset yhteydet (eng. relationships). Codd havaitsi, ett\u00e4 normalisoimattomat taulut johtavat helposti ongelmiin, joita h\u00e4n kutsui anomalioiksi. N\u00e4iden vaikutus on, ett\u00e4 tietoa voi olla mahdotonta lis\u00e4t\u00e4, muokata tai poistaa siten, ett\u00e4 operaatio rajautuisi vain yhden entiteetin tietoihin. Tietojen esitt\u00e4miseen ja k\u00e4sittelyyn sovelletaan joukko-oppiin perustuvaa relaatiotietokantateoriaa.</p> <p>Tietokantateorian sanastoa</p> <p>Relaatiotietokanta = Relaatiomalliin perustuvan tietokannan hallintaj\u00e4rjestelm\u00e4n avulla toteutettu tietokanta Relaatio, taulu = Rakenteeltaan samanlaisten monikoiden joukko. (relation, table) Yhteys = kahden taulun v\u00e4linen suhde (eng. relationship) Rivi, monikko = Vaakasuuntainen rivi taulussa (eng. row, tuple) Sarake, ominaisuus, m\u00e4\u00e4rite = Pystysuuntainen sarake taulussa (eng. column) Alkio, solu = Taulun solu (eng. cell, item) Arvo = Taulun solun sis\u00e4lt\u00f6 (eng. value)</p> <p>L\u00e4hde: Relaatiotietokantasanasto, Harri Laine, Helsingin Yliopisto</p> <p>Huomaa, ett\u00e4 yll\u00e4 esitelty monikko on englanniksi tuple. Pythonia osaaville t\u00e4m\u00e4 on entuudestaan tuttu sekvenssitietotyyppi. Relaatiotietokannan taulu voidaan siis n\u00e4hd\u00e4 listana monikkoja: ja n\u00e4in database-connectorin cursor sen usein palauttaakin.</p> <pre><code>taulu: list[tuple[int, str, int]] = [\n    (1, \"Rose\", 167),\n    (2, \"Lisa\", 182),\n    (3, \"Jack\", 180),\n]\n</code></pre> <p>Kielen SQL syntyyn Codd ei suoraan osallistunut, mutta h\u00e4nen ty\u00f6ns\u00e4 innoitti muita tutkijoita kehitt\u00e4m\u00e4\u00e4n kielt\u00e4. Ty\u00f6 jatkui IBM:ll\u00e4, tutkimusprojektissa nimelt\u00e4\u00e4n System/R, jossa Donald D. Chamberlin ja kollegat kehittiv\u00e4t SEQUEL (Structured English Query Language) -kielen, joka my\u00f6hemmin lyhennettiin SQL:ksi. SQL:n ensimm\u00e4inen versio julkaistiin 1970-luvun lopulla, ja se on sittemmin kehittynyt merkitt\u00e4v\u00e4sti. SQL on nyky\u00e4\u00e4n standardoitu kieli, jota k\u00e4ytet\u00e4\u00e4n laajalti relaatiotietokantojen hallintaan ja tiedon k\u00e4sittelyyn. Varsinainen kanta, jossa t\u00e4t\u00e4 uutta deklaratiivista englantia muistuttavaa kielt\u00e4 alettiin k\u00e4ytt\u00e4\u00e4, oli SEQUEL-XRM, ja vuosi oli 1974. Saman vuosikymmenen aikana kehittyi SEQUEL/2, joka my\u00f6hemmin nimettiin uudelleen SQL:ksi juridisten syiden takia. IBM sulki projektin 1979, mutta projektin aikana kieli kuitenkin todettiin toteutuskelpoiseksi, joskin sen ajan laitteistoteknologia vaati k\u00e4ytt\u00e4j\u00e4lt\u00e4 merkitt\u00e4v\u00e4\u00e4 k\u00e4rsiv\u00e4llisyytt\u00e4. <sup>2</sup></p> <p>I remember seeing a demonstration of System R in the late 1970s. It had lots of \u201cwow\u201d factor, but on the hardware technology available at the time, even a simple query took minutes to run.</p> <p>\u2014 John L. Viescas <sup>2</sup></p>"},{"location":"data_alustat/historia/#kuin-excel","title":"Kuin Excel?","text":"<p>Tietokannoista tai tauluista puhuttaessa tulee herk\u00e4sti mieleen Excel tai Google Spreadsheet. Taulukkolaskentaohjelman tauluun on toki mahdollista k\u00e4sin kirjata hyv\u00e4kin tietokantamalli, mutta kukaan ei my\u00f6sk\u00e4\u00e4n est\u00e4 tilannetta, jossa tietomalli on tietokoneen n\u00e4k\u00f6kulmasta kaoottinen. Alla esimerkki taulusta, joka voi olla jollekin ihmisyksil\u00f6lle t\u00e4ysin j\u00e4rkeenk\u00e4yp\u00e4, mutta ei koneluettava.</p> Name Salary GSM Phone Jack Bauer $100 k +358441234123 112 ja sit 911 Bond, James 30*10^6 040 1234 777 08 111 2222 James Bond 30e6 007 &lt;= K\u00e4ytt\u00e4\u00e4 vain tota Lisa 100,000.0 \u00a3 N/A 09 222 4444 -- \"\" -- -- \"\" -- Toi on m\u00f6kin numero =&gt; 05 333 7777 <p>Jotta tieto on j\u00e4rjestett\u00e4viss\u00e4 mill\u00e4\u00e4n tavoin normalisoiduksi, pit\u00e4\u00e4 kunkin rivin taulussa noudattaa yht\u00e4, selke\u00e4\u00e4 skeemaa. Mik\u00e4li l\u00e4hdedata olisi alla olevan skeeman mukaista, olisi sit\u00e4 jo jossain m\u00e4\u00e4rin mahdollista alkaan normalisoida pidemm\u00e4lle.</p> <pre><code>erDiagram\n    CUSTOMER {\n        int    customer_id\n        string first_name\n        string last_name\n        int    salary\n        string mobile_phone\n        string landline_phone\n    }</code></pre>"},{"location":"data_alustat/historia/#normalisointi","title":"Normalisointi","text":"<p>Aiemmin mainitun takia tietokannan taulut normalisoidaan eli hajautetaan useisiin tauluihin ja taulujen v\u00e4lisi\u00e4 suhteita kuvataan avaimilla ja viiteavaimilla. Yksitt\u00e4isen entiteetin tai taulun sarakkeet eiv\u00e4t sis\u00e4ll\u00e4 riippuvuuksia toisiinsa; tiedolla on suora riippuvuus vain ja ainoastaan taulun prim\u00e4\u00e4riavaimeen, joka on useimmiten keinotekoinen, juokseva kokonaisluku. Mik\u00e4li k\u00e4ytt\u00e4j\u00e4 haluaa tulostaa esimerkiksi ostotapahtumasta kuitin, tietoa pit\u00e4\u00e4 hakea ja yhdist\u00e4\u00e4 useista eri tauluista, kuten: <code>invoice</code>, <code>invoice_line_item</code>, <code>product</code>, <code>customer</code>.</p>"},{"location":"data_alustat/historia/#normaalimuodot","title":"Normaalimuodot","text":"<p>Codd jakoi tietokantojen normalisoinnin asteet j\u00e4rjestysluvuilla eri muotoihin, jotka ovat ensimm\u00e4inen, toinen ja kolmas normaalimuoto. N\u00e4ist\u00e4 k\u00e4ytet\u00e4\u00e4n lyhenteit\u00e4: 1NF, 2NF ja 3NF. Muissa teoksissa tai l\u00e4hteiss\u00e4 saattaa t\u00f6rm\u00e4t\u00e4 my\u00f6s 0NF, 4NF, 5NF tai BCNF -lyhenteisiin.</p> <p>N\u00e4iden vaatimukset ovat lyhyesti:</p> <ul> <li>1NF : Taulun jokainen sarake sis\u00e4lt\u00e4\u00e4 vain yhden arvon</li> <li>2NF : Taulun jokainen sarake on suoraan riippuvainen prim\u00e4\u00e4riavaimesta</li> <li>3NF : Taulun jokainen sarake on suoraan riippuvainen prim\u00e4\u00e4riavaimesta, eik\u00e4 muiden sarakkeiden kautta</li> </ul>"},{"location":"data_alustat/historia/#esimerkki-puhelinnumerot","title":"Esimerkki: Puhelinnumerot","text":"<p>K\u00e4yt\u00e4nn\u00f6ss\u00e4 t\u00e4m\u00e4 ajaa siihen, ett\u00e4 useimmat normalisoidun tietokannan taulut edustavat joitain entiteettej\u00e4. Yksi taulu voi olla customer, toinen phone numbers, ja niin edelleen. Tietokantaj\u00e4rjestelm\u00e4 yll\u00e4pit\u00e4\u00e4 n\u00e4iden taulujen v\u00e4lisi\u00e4 suhteita. Alla esimerkki normalisoidusta tietokannasta, jossa on kolmen entiteetit taulut: <code>CUSTOMER</code>, <code>PHONENUMBER</code> ja <code>ANNUAL_SALARY</code>. Lis\u00e4ksi on taulu <code>CUSTOMER_PHONENUMBER</code>, joka yhdist\u00e4\u00e4 asiakkaat ja heid\u00e4n puhelinnumeronsa. T\u00e4m\u00e4 on tarpeellinen many-to-many -suhteiden mallintamiseksi. Sama puhelinnumero, varsinkin landline, voi olla useammalla asiakkaalla. Toisaalta asiakkaalla voi olla useampi puhelinnumero.</p> <pre><code>erDiagram\n    CUSTOMER ||--o{ CUSTOMER_PHONENUMBER : associates_with\n    PHONENUMBER ||--o{ CUSTOMER_PHONENUMBER : is\n    CUSTOMER ||--o{ ANNUAL_SALARY : has\n\n    CUSTOMER {\n        int    customer_id\n        string first_name\n        string last_name\n    }\n\n    CUSTOMER_PHONENUMBER {\n        int    contact_id\n        int    fk_customer_id\n        int    fk_phone_number_id\n    }\n\n    PHONENUMBER {\n        int    phone_number_id\n        string phone_number\n        string phone_type\n    }\n\n    ANNUAL_SALARY {\n        int    salary_id\n        int    fk_customer_id\n        int    salary_year\n        string currency\n        int    salary\n    }</code></pre> <p>Lopulta alkuper\u00e4isen kaltaisen, yhden ison taulun presentaation, saa muodostettua liitt\u00e4m\u00e4ll\u00e4 taulut yhteen prim\u00e4\u00e4ri- ja viiteavaimia k\u00e4ytt\u00e4en. T\u00e4m\u00e4 vaihe tunnetaan nimell\u00e4 denormalization. Huomaa, ett\u00e4 taulujen liitt\u00e4minen (eng. joining) on I/O:n n\u00e4k\u00f6kulmasta kallis operaatio. Operatiiviset kannoissa normalisointi est\u00e4\u00e4 tiedon p\u00e4ivitt\u00e4misest\u00e4 tai poistamisesta syntyvi\u00e4 anomalioita, mutta analytiikkaan k\u00e4ytett\u00e4viss\u00e4 kannoissa, jotka esitell\u00e4\u00e4n hieman alempana, on usein hy\u00f6dyllist\u00e4 mallintaa tieto hieman v\u00e4hemm\u00e4n normalisoituun muotoon. \u00c4\u00e4rimm\u00e4inen normaliuden purkamisen muoto on One Big Table; hieman yleisempi on analytiikan tarpeisiin suunniteltu t\u00e4htiskeema.</p> <p>SQL on tietovarastoissa yleinen kieli, joten liitet\u00e4\u00e4n normalisoidut taulut yhdeksi suurekti tauluksi SQL:\u00e4\u00e4 hy\u00f6dynt\u00e4en esimerkin vuoksi. Alla on adminitionin alla esimerkkidataa, joka noudattaa yll\u00e4 m\u00e4\u00e4riteltyjen taulujen dataa:</p> CustomerAnnual salaryPhone numberCustomer-Phonenumber customer_id first_name last_name 1 John Doe 2 Jane Smith 3 Alice Johnson salary_id fk_customer_id salary_year currency salary 1 1 2023 USD 60000 2 2 2023 USD 55000 3 3 2023 USD 70000 phone_number_id phone_number phone_type 1 040 6548 471 gsm 2 08 618 9910 landline contact_id fk_customer_id fk_phone_number_id 1 1 1 2 2 2 3 3 1 4 3 2 <p>Info</p> <p>Lukuohje:</p> <pre><code>* John Doe (1) has GSM.\n* Jane Smith (2) has Landline. \n* Alice Johnson (3) has both GSM and Landline.\n</code></pre> <p>Datat voidaan joinata seuraavalla queryll\u00e4:</p> Klikkaa query esiin <pre><code>SELECT\n    CONCAT(c.first_name, ' ', c.last_name) AS full_name,\n    ann.salary,\n    ann.currency,\n    pn.phone_type,\n    pn.phone_number\nFROM customer c\nLEFT JOIN annual_salary ann ON c.customer_id = ann.fk_customer_id\nLEFT JOIN customer_phonenumber AS mm ON c.customer_id = mm.fk_customer_id\nLEFT JOIN phonenumber pn ON mm.fk_phone_number_id = pn.phone_number_id;\n</code></pre> <p>Yhdistynyt data n\u00e4ytt\u00e4\u00e4 seuraavalta:</p> full_name salary currency phone_type phone_number 0 John Doe 60000 USD gsm 040 6548 471 1 Jane Smith 55000 USD landline 08 618 9910 2 Alice Johnson 70000 USD landline 08 618 9910 3 Alice Johnson 70000 USD gsm 040 6548 471 <p>Teht\u00e4v\u00e4</p> <p>Pohdi, kuinka esitt\u00e4isit palkan vertailukelpoisena eri valuutoissa. Taulussa on valuuttakoodi, mutta se ei ole sin\u00e4ll\u00e4\u00e4n vertailukelpoinen. Taulussa on my\u00f6s vuosiluku. Miten ratkaisisit t\u00e4m\u00e4n ongelman?</p> <p>Teht\u00e4v\u00e4</p> <p>Merkkijonokentt\u00e4 \"phone_type\" on yh\u00e4 normalisoimatta. Kuinka ratkaisisit t\u00e4m\u00e4n ongelman?</p>"},{"location":"data_alustat/historia/#tietovarastot","title":"Tietovarastot","text":"<p>K\u00e4ytt\u00f6j\u00e4rjestelmien ja ohjelmointikielien runsaus sek\u00e4 standardien puute muodostivat kaaoksen 1960-luvua edelt\u00e4v\u00e4n\u00e4 aikana. Vuosikymmen 1960 oli IBM 360 -suurtietokoneiden ja saman yrityksen tietokannan hallintaj\u00e4rjestelm\u00e4n, IMS:n, valtaaikaa. T\u00e4ll\u00f6in, kauan sitten, eli ennen 1980- ja 1990-lukujen vaihdetta, samoja kantoja k\u00e4ytettiin sek\u00e4 operatiiviseen k\u00e4ytt\u00f6\u00f6n ett\u00e4 datan analysointiin. N\u00e4m\u00e4 transaktiokannat mahdollistivat yrityksille nykyp\u00e4iv\u00e4n\u00e4 itsest\u00e4\u00e4nselvi\u00e4 prosesseja, kuten k\u00e4teisnoston pankkiautomaatilla tai lennon varauksen, mutta niit\u00e4 k\u00e4ytettiin my\u00f6s analyyttisiin kyselyihin. Mik\u00e4li yrityksen johtoa kiinnosti kokonaismyynti tammikuussa, data haettiin samasta tuotantokannasta, mihin se oli kirjoitettukin. Kyselykieli oli sek\u00e4 OLTP- ett\u00e4 OLAP-kyselyiss\u00e4 yleisimmin SQL.</p>"},{"location":"data_alustat/historia/#datan-maaran-kasvu","title":"Datan m\u00e4\u00e4r\u00e4n kasvu","text":"<p>Datan m\u00e4\u00e4r\u00e4n sek\u00e4 analytiikan tarpeen kasvaessa yritykset alkoivat  integroida tuotantoj\u00e4rjestelmien dataa keskitettyyn varastoon, joka on optimoitu OLAP-k\u00e4ytt\u00f6\u00e4 varten. N\u00e4ist\u00e4 j\u00e4rjestelmist\u00e4 k\u00e4ytet\u00e4\u00e4n nime\u00e4 tietovarasto (eng. data warehouse). Tietovarasto  sis\u00e4lt\u00e4\u00e4 siis yhden tai useamman tuotantokannan dataa. 1990-luvulla IBM:n haastaja  eli Teradata-yhti\u00f6 mahdollisti MPP:n (eng. massively parallel processing) eli massiivisen rinnakkaislaskennan. 2000 luvun puolella kuvioihin astui hajautettuun tallennukseen ja laskentaan perustuva Apache Hadoop, jonka reppusel\u00e4ss\u00e4 IBM, Cloudera, Hortonworks ja muut ratsastivat. Hadoop itsess\u00e4\u00e4n talsii Googlen GFS:n (Google File Systemin) jalanj\u00e4ljiss\u00e4.</p> <p>Sanastoa</p> <ul> <li>OLTP = Transaktioihin liittyv\u00e4t kyselyt (Online Transaction Processing)</li> <li>OLAP = Analytiikkaan liittyv\u00e4t kyselyt (Online Analytical Processing)</li> <li>HTAP = Arkkitehtuuri, jossa k\u00e4ytet\u00e4\u00e4n yht\u00e4 tietokantaa sek\u00e4 transaktioihin ett\u00e4 analytiikkaan (Hybrid Transactional/Analytical Processing)</li> </ul> <p>Huomaa, ett\u00e4 HTAP on ainakin toistaiseksi enemm\u00e4n teoriaa kuin k\u00e4yt\u00e4nt\u00f6\u00e4. Jos haluat tutustua aiheeseen, lue esimerkiksi TiDB:n postaus The Beauty of HTAP: Defining a Modern Data Architecture with TiDB. L\u00e4ht\u00f6kohtaisesti t\u00e4ll\u00e4 kurssilla kuitenkin oletetaan, ett\u00e4 OLTP:t\u00e4 varten on yksi kantaratkaisu ja OLAP:ia varten toinen.</p> <p>Teht\u00e4v\u00e4</p> <p>Kannattaa v\u00e4hint\u00e4\u00e4nkin silm\u00e4ill\u00e4 papereita, jotka alunperin her\u00e4ttiv\u00e4t Apache Nutch -kehitt\u00e4jien kiinnostuksen, ja siten antoivat sys\u00e4yksen Hadoopin kehitykselle:</p> <ul> <li>Google File System</li> <li>MapReduce: Simplified Data Processing on Large Clusters</li> </ul>"},{"location":"data_alustat/historia/#tietokanta-ja-varasto-rinnakkain","title":"Tietokanta ja -varasto rinnakkain","text":"<p>On t\u00e4rke\u00e4\u00e4 ymm\u00e4rt\u00e4\u00e4, ett\u00e4 tietovarasto sis\u00e4lt\u00e4\u00e4 kopion useiden l\u00e4hdej\u00e4rjelmien datasta. Tietovarasto ei ole siis vaihtoehto operatiiviselle kannalle. Se on tekninen ratkaisu, joka mahdollistaa analyyttiset kyselyt, jotka olisivat liian raskaita operatiiviselle kannalle - mutta se ei suinkaan korvaa perinteist\u00e4 tietokantaa OLTP-k\u00e4ytt\u00f6tapauksissa.</p> <p>Tip</p> <p>Yll\u00e4 mainitut HTAP-j\u00e4rjestelm\u00e4t ovat lupaus tulevaisuudesta, jossa n\u00e4m\u00e4 muodostavat jonkin sortin keskitetyn monitoimikoneen, joka pystyy suorittamaan sek\u00e4 transaktioita ett\u00e4 analytiikkaa. T\u00e4m\u00e4 ei kuitenkaan tarkoita, ett\u00e4 n\u00e4m\u00e4 olisivat my\u00f6sk\u00e4\u00e4n \"zero copy\", vaan konepellin alla voidaan hyvinkin s\u00e4il\u00f6\u00e4 data rivi- tai saraketasolla duplikaatteina.</p>"},{"location":"data_alustat/historia/#tietojarvi","title":"Tietoj\u00e4rvi","text":""},{"location":"data_alustat/historia/#data-lake","title":"Data Lake","text":"<p>Tietoj\u00e4rvi (engl. data lake) syntyi Hadoop-ekosysteemin my\u00f6t\u00e4. Tietoj\u00e4rvi on suuri, hajautettu tiedostoj\u00e4rjestelm\u00e4, johon dataa voidaan tallentaa raakamuodossa. Tietoj\u00e4rvi on tarkoitettu suurten datam\u00e4\u00e4rien tallentamiseen ja analysointiin. Tietolammen riskin\u00e4 on, ett\u00e4 yhteen laariin kaadettu skeematon data muodostaa ns. datasuon (engl. data swamp). Dataa siis on terakaupalla, mutta kukaan ei tied\u00e4, miss\u00e4 se lienee.</p> <p>Tietoj\u00e4rvi on kenties helpoin selitt\u00e4\u00e4 koodin avulla. Kuvitellaan koodi, jossa hajautettu laskentamoottori Apache Spark lataa dataa Amazon S3:sta, k\u00e4sittelee sit\u00e4 ja tallentaa tuloksen takaisin S3:een Parquet-formaatissa. T\u00e4ss\u00e4 tapauksessa Amazon S3 on siis Tietoj\u00e4rvi; Apache Spark on laskentamoottori, joka k\u00e4sittelee dataa; ja Parquet on tallennusformaatti, joka on optimoitu analytiikkaa varten.</p> <p>Alla oleva koodi tekee seuraavat vaiheet:</p> <ul> <li>Lataa kaikki .png-tiedostot Amazon S3:sta</li> <li>K\u00e4sittelee kuvat ja laskee niist\u00e4 feature-vektorin koneoppimismallin sy\u00f6tett\u00e4 varten</li> <li>Tallentaa sek\u00e4 kuvadatan ett\u00e4 vektorit takaisin j\u00e4rveen (mutta eri lokaatioon) </li> </ul> <pre><code># Path to the dataset\ndataset_path = \"s3://bucket-name/path/to/2024/10/31/\"\n\n# Read PNG files from the given path\ndf = spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.png\").load(dataset_path)\n\n# The df will contain columns:\n# * path: StringType\n# * modificationTime: TimestampType\n# * length: LongType\n# * content: BinaryType\n\ndef derive_feature_vector(content):\n    # Process the content and return a feature vector\n    return [1.0, 2.0, 3.0]\n\nudf_feat_desc = F.udf(derive_feature_vector, ArrayType(DoubleType()))\n\n# Add a new column with a feature vector\ndf_feat = df.withColumn(\"feature_vector\", udf_feat_desc(df.content))\n\n# Write the DataFrame to Parquet format\noutput_path = \"s3://bucket-name/output/feature-vector-table/2024-10-31-table.parquet\"\ndf_feat.write.mode(\"append\").parquet(output_path)\n</code></pre> <p>Jokin my\u00f6hempi koodinp\u00e4tk\u00e4 voisi sitten ladata t\u00e4m\u00e4n Parquet-tiedoston ja k\u00e4ytt\u00e4\u00e4 sit\u00e4 koneoppimismallin opettamiseen. Esimerkiksi n\u00e4in:</p> <pre><code># Lataa kaikkien p\u00e4ivien feature-vektorit\ndf = spark.read.parquet(\"s3://bucket-name/output/feature-vector-table/\")\n\n# K\u00e4yt\u00e4 feature-vektoreita koneoppimismallin opettamiseen\nmodel = SomeMLModel().fit(df)\n</code></pre> <p>Yll\u00e4 oleva esimerkki on luonnollisesti yksinkertaistettu rankasti, mutta toivon mukaan se demonstroi dataj\u00e4rven olemusta: dataj\u00e4rvi on vain tallennuspaikka, johon voi dumpata mit\u00e4 tahansa dataa, ja kyseisen datan voi ladata jollakin laskenta- tai analytiikkaty\u00f6kalulla. Dataj\u00e4rvi ei siis ole jokin tietty RDBMS. Ei ole tietokantaa. Ei ole koko tietokantaserveri\u00e4. On vain dataa j\u00e4rvess\u00e4.</p>"},{"location":"data_alustat/historia/#modern-data-stack","title":"Modern Data Stack","text":"<p>Yll\u00e4 olevasta materiaalista on jo toivon mukaan selvinnyt, ett\u00e4 ty\u00f6kaluja voi olla useita rinnakkain - esimerkiksi: operatiivinen tietokanta (tai monta), tietovarasto, tietoj\u00e4rvi ja jokin laskentaklusteri, jolla j\u00e4lkimm\u00e4ist\u00e4 k\u00e4sitell\u00e4\u00e4n. Jos t\u00e4h\u00e4n liitet\u00e4\u00e4n viel\u00e4 ty\u00f6kaluja, joilla dataa tuodaan ja vied\u00e4\u00e4n, sek\u00e4 ty\u00f6kaluja, joilla dataa visualisoidaan, niin kokonaisuudesta voidaan k\u00e4ytt\u00e4\u00e4 sanaa data-alusta (eng. data platform). Data-alusta voi olla valtava, keskitetty yksi ty\u00f6kalu, tai se voi olla hajautettu, pienist\u00e4 modulaarisista palasista koostuva kokonaisuus. J\u00e4lkimm\u00e4iseen viitataan usein termill\u00e4 moderni data stack.</p> <p>Fishtown Analyticsin Tristan Handy tiivist\u00e4\u00e4 modernin tietoinfran  (eng. modern data stack) nykyisen vaiheen alkaneen vuonna 2012 Amazon Redshiftin my\u00f6t\u00e4. H\u00e4n listaa kolme vaihetta, jotka ovat leikkis\u00e4sti nimetyt: </p> <ul> <li>ensimm\u00e4isen kambrikauden r\u00e4j\u00e4hdys 2012\u20132016</li> <li>k\u00e4ytt\u00f6\u00f6nottokausi 2016\u20132020</li> <li>ja h\u00e4nen ennustelmiensa mukaan toinen kambrikauden r\u00e4j\u00e4hdys 2020\u20132025</li> </ul> <p>Tristan ei mainitse Hadoopia sanallakaan kirjoituksessaan, mutta mainitsee Snowflaken sek\u00e4 Google BigQueryn sek\u00e4 useita muita tietoinfraan liittyvi\u00e4 tuotteita kuten Looker, Fivetran, Stitch, Redash ja heid\u00e4n oma tuotteensa eli dbt.</p> <p>Teht\u00e4v\u00e4</p> <p>Lue Tristan Handyn tuoreempi kirjoitus helmikuulta 2024, Is the \"Modern Data Stack\" Still a Useful Idea?. Miten h\u00e4n vastaa otsikon kysymykseen?</p> <p>Oli termi modern data stack nykyisin pelkk\u00e4 meemi tai ei, sen aikakauden dataratkaisut j\u00e4ttiv\u00e4t muutoksia j\u00e4lkeens\u00e4. N\u00e4it\u00e4 muutoksia, verrattuna legacy-aikoihin, ovat muiden muassa:</p> <ul> <li>ETL vs. ELT: Perinteisesti data on siirretty ETL:n (Extract, Transform, Load) avulla. Moderneissa j\u00e4rjestelmiss\u00e4 data alettiin tuoda tietovaraston stagingiin <code>as-raw-as-possible</code>-hengess\u00e4, ja muokkaus (Transform) laskettiin tietovarastossa eik\u00e4 ingestion toolilla.</li> <li>On-Prem vs. Pilvi: Useat t\u00e4ll\u00e4 kurssilla mainituista teknologioista toimivat l\u00e4ht\u00f6kohtaisesti pilvess\u00e4. Osa on my\u00f6s hybrid/on-prem.</li> <li>Monoliitti vs. Best-of-breed: Perinteisesti tietovarasto on ollut monoliittinen, mutta modernissa ekosysteemiss\u00e4 on useita eri ty\u00f6kaluja, jotka on integroitu toisiinsa.</li> <li>Eriytetty laskenta ja tallennus: Perinteisesti tietovarastossa tallennus ja sen laskenta ovat olleet saman instanssin sis\u00e4ll\u00e4. Jos skaalaat instanssia suuremmaksi, hinta nousee sek\u00e4 tallenuskapasiteetin ett\u00e4 laskentehon mukaan, vaikka olisit tarvinnut vain toista. Modernissa ekosysteemiss\u00e4 laskenta on irrotettu (eng. decoupled) tallennuksesta. Laskenta tapahtuu esimerkiksi Apache Sparkilla, tallennus esimerkiksi Amazon S3:een. N\u00e4it\u00e4 voidaan skaalata erikseen.</li> <li>Indeksointi: Usein tietovarastot ovat indeksoimattomia. Tietovarasto tied\u00e4 taulujen v\u00e4lisist\u00e4 linkeist\u00e4 (primary keys, foreign keys) mit\u00e4\u00e4n. Hakuja optimoidaan toisella tavoin.</li> </ul>"},{"location":"data_alustat/historia/#data-lakehouse","title":"Data Lakehouse","text":"<p>Kuten yll\u00e4 on mainittu, Hadoop yhdistet\u00e4\u00e4n usein termiin tietoallas eli data lake, joka on pahimmillaan yrityksen jaettua levy\u00e4 muistuttava datan hautausmaa tai \"data swamp\". Handy m\u00e4\u00e4rittelee modernin siten, ett\u00e4 moderni datan aikakausi alkoi Hadoopin ja perinteisten tietoaltaiden kuoppauksesta. Ekosysteemiin on sittemmin liittynyt melkoinen m\u00e4\u00e4r\u00e4 erilaisia ty\u00f6kaluja ja uudenlaisia paradigmoja. Snowflaken yksi merkitt\u00e4v\u00e4 kilpailija on Databricks, jonka tuotteen syd\u00e4men\u00e4 toimii heid\u00e4n aloittamansa Apache Spark. Sek\u00e4 Snowflake ett\u00e4 Hadoop, kuten my\u00f6s monet muut toimijat, eriyttiv\u00e4t laskennan ja tallennuksen. Tallennustilana toimii tietoallas, tavallaan, mutta mieluiten siten, ett\u00e4 datan skeema ja sijainti yll\u00e4pidet\u00e4\u00e4n katalogissa. </p> <p>Nyky\u00e4\u00e4n t\u00e4st\u00e4 hybridist\u00e4 k\u00e4ytet\u00e4\u00e4n termi\u00e4 Data Lakehouse (Data Lake + Data Warehouse), ja sen pyrkimyksen\u00e4 on yhdist\u00e4\u00e4 n\u00e4iden parhaat puolet. N\u00e4m\u00e4 \"parhaat puolet\" tiivistyv\u00e4t usein lyhenteeseen ACID, joka on ik\u00e4\u00e4n kuin laatukriteerist\u00f6 tai m\u00e4\u00e4ritelm\u00e4 tietokantaoperaatioille, jotka tyypillisesti ovat relaatiotietokantahallintaj\u00e4rjestelm\u00e4n (RDBMS) heini\u00e4. Ideaalitilanteessa Lakehouse k\u00e4ytt\u00e4ytyy kuin Warehouse, mutta data on tallennettuna edulliseen Lakeen. T\u00e4ll\u00f6in \"warehouse\" on esimerkiksi Apache Hive, ja \"lake\" on esimerkiksi Amazon S3. ACID k\u00e4sitell\u00e4\u00e4n my\u00f6hemmin Storage- eli tallennuskerroksen yhteydess\u00e4. Toisin kuin tyypillinen warehouse, lakehouse mahdollistaa kuitenkin mink\u00e4 tahansa tiedon tallentamisen altaaseen (kuvat, videot, raaka sensoridata, ...)</p>"},{"location":"data_alustat/historia/#landscape-ja-moderni-tanaan","title":"Landscape ja Moderni t\u00e4n\u00e4\u00e4n","text":"<p>Modern data stack on siit\u00e4 hassu sanavalinta, ett\u00e4 \"modern\" on kohtalaisen suhteellinen k\u00e4site - aivan samalla tavalla kuin big datan \"big\". Aika n\u00e4ytt\u00e4\u00e4, j\u00e4\u00e4v\u00e4tk\u00f6 kummatkin termit el\u00e4m\u00e4\u00e4n, jolloin joka vuosi sek\u00e4 modernius ett\u00e4 suuruus m\u00e4\u00e4rittyv\u00e4t uusiksi. Oli termi mik\u00e4 tahansa, data landscape pit\u00e4nee katsastaa joka vuosi hieman uusin silmin, sill\u00e4 muutos ja kasvu on ollut 2000-luvulla nopeaa. Termit ja trendit tulevat ja menev\u00e4t, mutta tarve datan k\u00e4sittelyyn, analytiikkaan ja liiketoiminnan ongelmien ratkaisemiseen pysyy.</p> <p>On syntynyt my\u00f6s liikehdint\u00e4\u00e4 suuntaan, jossa pienemmille toimijoille tarjotaan ei-niin-big-datan ty\u00f6kaluja, kuten DuckDB, jota kaupallistaa MotherDuck, ja konsultaatiopalveluiden kautta my\u00f6s DuckDB Labs. SaaS-ty\u00f6kalujen luomalle best of breed -hajautukselle on syntynyt my\u00f6s vastarintaa, jossa unification on tavoitteena. Esimerkiksi Microsoft Fabric pyrkii olemaan yksi ty\u00f6kalu, joka pyrkii yhdist\u00e4m\u00e4\u00e4n koko data stackin yhden nimikkeen alle.</p> <p></p> <p>Kuvio 1: Ekosysteemien muutos vuosista 2012 alkaen. Ty\u00f6kalujen m\u00e4\u00e4r\u00e4 on kasvanut reippaalla tahdilla. (L\u00e4hde: Matt Turck)</p> <p>Teht\u00e4v\u00e4</p> <p>Kuvassa n\u00e4kyv\u00e4 2023 arkkitehtuuri l\u00f6ytyy interaktiivisena versiona t\u00e4\u00e4lt\u00e4: FirstMark | 2023 MAD (ML/AI/Data) Landscape. Tutustu otsikkotasolla graafiin. Mit\u00e4 eri kategorioita kokonaisuuteen kuuluu?</p> <p>Tip</p> <p>Useat muutkin yritykset toimivat kuten MotherDuck eli kaupallistavat avointa l\u00e4hdekoodia. N\u00e4ihin lukeutuvat muiden muassa Databricks (Spark), Nginx, MongoDB, Confluent (Kafka), HashiCorp (Terraform), Red Hat (RHEL, CentOS). Bisnesmallin pohjalla oleva p\u00e4\u00e4tuote on open source, mutta sit\u00e4 kaupallistetaan yritysasiakkaille managed SaaS-palveluna. T\u00e4m\u00e4n voi n\u00e4hd\u00e4 datan k\u00e4yt\u00f6n demokratisointina: yrityksell\u00e4 ei tarvitse olla varaa Clouderan, Oraclen, IBM:n tai muiden j\u00e4ttien lisensseihin k\u00e4sitell\u00e4kseen dataa.</p>"},{"location":"data_alustat/historia/#historia-videona","title":"Historia videona","text":"<p>Video 1: Hannes M\u00fchleisen, joka on DuckDB:n luoja ja DuckDB Labs:n toimitusjohtaja, kertoo tietokantojen historiasta. Hannes on puhunut my\u00f6s Helsinki Data Week 2025:ssa ihan Suomen kamaralla.</p>"},{"location":"data_alustat/historia/#lahteet","title":"L\u00e4hteet","text":"<ol> <li> <p>Codd, E.F. A Relational Model of Data for Large Shared Data Banks. https://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf\u00a0\u21a9</p> </li> <li> <p>Viescas, J. SQL Queries for Mere Mortals: A Hands-On Guide to Data Manipulation in SQL, 4th Edition. Addison-Wesley Professional, 2018.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"data_alustat/hyodyt/","title":"Hy\u00f6dyt bisnekselle","text":"<p>Datan tallentaminen maksaa. Mik\u00e4li yritys siirt\u00e4\u00e4 tiedot operatiivisista kannoista analyyttisiin kantoihin (warehouse, lake, lakehouse), datan s\u00e4ilytyksen ja k\u00e4sittelyn kulut luonnollisesti kasvavat. Mik\u00e4li dataa s\u00e4il\u00f6t\u00e4\u00e4n mikropalveluista vastaavien tiimien omien kantojen ulkopuolella, t\u00e4st\u00e4 aiheutuu my\u00f6s uusia tarpeita kommunikaatiolle. Kommunikaatio on l\u00e4ht\u00f6kohtaisesti vaikeaa. Lis\u00e4ksi jokainen uusi j\u00e4rjestelm\u00e4, jossa tietoa s\u00e4il\u00f6t\u00e4\u00e4n, lis\u00e4\u00e4 my\u00f6s tietoturvariski\u00e4. Lis\u00e4\u00e4ntyneet kulut eiv\u00e4t v\u00e4ltt\u00e4m\u00e4tt\u00e4 edes kuittaa itse\u00e4\u00e4n: vain murto-osa (~15%) big data projekteista onnistuu tuottamaan selke\u00e4\u00e4 bisnesarvoa tavoitteiden mukaisesti. T\u00e4st\u00e4 her\u00e4\u00e4 kysymys: mit\u00e4 hy\u00f6ty\u00e4 siit\u00e4 on businekselle?</p>"},{"location":"data_alustat/hyodyt/#hyodyt","title":"Hy\u00f6dyt","text":"<p>Hy\u00f6tyj\u00e4 siihen tilanteeseen verrattuna, ett\u00e4 tietoalustaa ei ole, ovat muiden muassa alla listatut. Vaihtoehto tietoalustan puuttumiselle on Excel-tiedostot ja muut kopiot tai dumpit.</p> <ul> <li>Datan laadun paraneminen. Loppuk\u00e4ytt\u00e4j\u00e4t uskaltavat luottaa dataan, joka on tallennettu yhteen paikkaan. T\u00e4m\u00e4 v\u00e4hent\u00e4\u00e4 datan duplikaatiota ja parantaa datan laatua.</li> <li>Tietosuojan paraneminen. Datan hallinta on keskitetty\u00e4, jolloin tietosuojan hallinta on helpompaa.</li> <li>Datakulttuurin kehittyminen. Datakulttuuri kehittyy, kun dataa k\u00e4ytet\u00e4\u00e4n liiketoiminnan p\u00e4\u00e4t\u00f6ksenteossa ja ty\u00f6nteon arjessa.</li> <li>Siilojen ja heimotietouden purku. Data-alustan k\u00e4ytt\u00f6\u00f6notto edellytt\u00e4\u00e4 yhteisty\u00f6t\u00e4 eri tiimien v\u00e4lill\u00e4. T\u00e4m\u00e4 purkaa siiloja ja heimotietoutta.</li> </ul> <p>Tip</p> <p>Jos termi heimostietous on vieras, tutustu asiaan. Englanniksi termi on tribal knowledge.</p> <p>Teht\u00e4v\u00e4</p> <p>Etsi esimerkkej\u00e4 yrityksist\u00e4, jotka ovat hy\u00f6tyneet big data -projekteista. Mit\u00e4 hy\u00f6tyj\u00e4 he ovat saaneet? L\u00f6yd\u00e4tk\u00f6 sek\u00e4 sellaisia esimerkkej\u00e4, jotka n\u00e4kyv\u00e4t suoraan asiakkaalle (esim. recommendation engine) ett\u00e4 sellaisia, jotka n\u00e4kyv\u00e4t yrityksen sis\u00e4ll\u00e4 (esim. ty\u00f6ntekj\u00f6iden tyytyv\u00e4isyyden parantaminen.)</p>"},{"location":"data_alustat/hyodyt/#projektien-kaatumisen-syyt","title":"Projektien kaatumisen syyt","text":"<p>Big data -projektien kaatuminen on yleinen aihe esimerkiksi Medium-sivuston postauksissa, LinkedIn-alustan keskusteluissa sek\u00e4 konsulttitalojen julkaisemissa artikkeleissa. Joitakin yleisi\u00e4, kirjoituksesta toiseen toistuvia syit\u00e4 ovat:</p> <ul> <li>Datan laadun t\u00e4rkeys aliarvioidaan. Garbage in, garbage out.</li> <li>Tavoitteiden hataruus. Tavoitteet ovat vaikeasti mitattavissa, eiv\u00e4t ole liiketoiminnan kannalta merkitt\u00e4vi\u00e4 tai realistia, tai tavoitteet ovat liian kauaskantoisia.</li> <li>Projektin v\u00e4\u00e4r\u00e4 omistajuus. Big data -alusta n\u00e4hd\u00e4\u00e4n teknologisena ratkaisuna, ei liiketoiminnallisena ratkaisuna. Mik\u00e4li data-alusta on \"IT-hanke\", se kaatuu l\u00e4hes varmasti.</li> <li>Raakadatan ker\u00e4\u00e4minen ilman tarkoitusta. Pelk\u00e4ll\u00e4 datan ker\u00e4\u00e4misell\u00e4 ei ole liiketoiminnallista arvoa. T\u00e4ss\u00e4 on kenties taustalla FOMO (Fear of Missing Out) eli \"koska muutkin, niin meid\u00e4nkin pit\u00e4\u00e4.\"</li> <li>Kulttuurin luominen ep\u00e4onnistuu. Jos ty\u00f6ntekij\u00e4t jatkavat ty\u00f6skentely\u00e4 vanhoilla tavoilla, ei datakulttuuria synny. Data-alustasta ei ole hy\u00f6ty\u00e4, jos sit\u00e4 ei k\u00e4ytet\u00e4.</li> <li>Oikea osaaminen puuttuu. Yritykselt\u00e4 puuttuu oikea osaaminen, ty\u00f6ntekij\u00f6ilt\u00e4 puuttuu resurssit kehitt\u00e4\u00e4 omaa osaamistaan, ja kenties rekryss\u00e4 etsit\u00e4\u00e4n yksisarvisia.</li> </ul> <p>Tip</p> <p>Jos data-alustan yksi hy\u00f6ty (ja samalla menestyksen vaatimus) on datakulttuurin ja datanlukutaidon kehittyminen, mieti, kuinka data-alustan luomisen voi ulkoistaa. Millainen ulkoistetun projektin tulee olla, jotta se kehitt\u00e4\u00e4 tilaajayrityksen sis\u00e4ist\u00e4 datakulttuuria?</p> <p>Vihje: vertaa t\u00e4t\u00e4 tietoturvan kulttuuriin. Tietoturva on yrityksen kaikkien ty\u00f6ntekij\u00f6iden vastuulla. Yksi tiimi ei voi \"hoitaa hommaa\". Tietoturva on my\u00f6s jatkuvaa ty\u00f6t\u00e4, ei yksitt\u00e4inen projekti.</p>"},{"location":"data_alustat/hyodyt/#onnistumisen-edellytykset","title":"Onnistumisen edellytykset","text":"<p>Yll\u00e4 mainitut syyt projektien kaatumiselle voi k\u00e4\u00e4nnet\u00e4\u00e4n my\u00f6s onnistumisen edellytyksiksi. Mik\u00e4li oletetaan aiempi lista riitt\u00e4v\u00e4n kattavaksi, niin tarkistuslista onnistumisen tielle voisi olla:</p>"},{"location":"data_alustat/hyodyt/#bisnestavoitteet","title":"Bisnestavoitteet","text":"<p>Data-alustalle asetetut tavoitteet ovat bisnesvetoisia ja mitattavissa. Tavoitteet ovat realistisia ja niiden saavuttamiseksi on olemassa suunnitelma. Ensimm\u00e4inen tavoite on matalan kynnyksen Proof of Concept (lyhyesti PoC), jonka tulisi tuottaa ensimm\u00e4isi\u00e4 realistisia tuloksia hyvinkin lyhyess\u00e4 ajassa (kuukausi tai kaksi). N\u00e4in data-alustajan kasaajat ja liiketoiminnan edustajat saavat k\u00e4siins\u00e4 jotain konkreettista, jonka avulla on helppo puhua samoista asioista.</p> <p>Projektia k\u00e4ynnist\u00e4ess\u00e4 on t\u00e4rke\u00e4\u00e4, ett\u00e4 teknologia tai lopputuote ei ole itseisarvo, vaan tavoitteet ovat liiketoiminnallisia. Ensimm\u00e4isiss\u00e4 palavereissa on hyv\u00e4 v\u00e4ltell\u00e4 turhia muotisanoja (eng. buzzword, kuten LLM, NLP, semantic layer, data vault) sek\u00e4 nimettyj\u00e4 teknologioita tai palveluntarjoajia (Apache Spark, Apache Kafka, Snowflake, AWS EMR, jne.) My\u00f6sk\u00e4\u00e4n pelkk\u00e4\u00e4n lopputulokseen, kuten \"me halutaan t\u00e4mm\u00f6nen interaktiivinen Dashboard\", ei kannata takertua. Eth\u00e4n siis tee datatiedett\u00e4 ihan vain datatieteen takia - tai siksi ett\u00e4 muutkin - vaan tarpeen m\u00e4\u00e4rittelem\u00e4n\u00e4.</p> <p>Tavoitteita laatiessa on t\u00e4rke\u00e4\u00e4 tavoittaa ja kuulla kaikkia niit\u00e4, joita projektissa ratkaistava ongelma koskettaa. Ota heid\u00e4t mukaan kokoukseen. Kun tied\u00e4t, ket\u00e4 ongelma koskettaa, voit kokeilla seuraavia:</p> <ol> <li>Rautakoodaa tai tee muutoin itse PoC, joka ratkaisee ongelman.</li> <li>Kysy loppuk\u00e4ytt\u00e4j\u00e4lt\u00e4, onko ratkaisu k\u00e4ytt\u00f6kelpoinen, ja kuinka se muuttaisi h\u00e4nen toimintaansa.</li> </ol> <p>Tip</p> <p>Kuvittele, ett\u00e4 olet myym\u00e4l\u00e4p\u00e4\u00e4llikk\u00f6 Kajaanin Tilpeh\u00f6\u00f6ri Oy:ss\u00e4. Aulassanne on Hype2Reality Oy -konsulttitalon toteuttavat asiakastyytyv\u00e4isyysmittaus, joka perustuu viiteen hymi\u00f6\u00f6n: , , , , , edustaen arvosanoja 1-5.</p> <p>Vastauksien m\u00e4\u00e4r\u00e4 ja hajonta pysyy samana, mutta keskiarvona tulokset ovat:</p> <p>Viikko 33:  (# 4)   Viikko 34:  (# 3)</p> <p>Kuinka korjaat t\u00e4m\u00e4n negatiivisen kehityssuunnan?</p> <p>Jos loppuk\u00e4ytt\u00e4j\u00e4 ei osaa kertoa, kuinka h\u00e4nen edess\u00e4\u00e4n n\u00e4kyv\u00e4 ratkaisu muuttaisi h\u00e4nen toimintaansa, on todenn\u00e4k\u00f6ist\u00e4, ett\u00e4 ratkaisu ei ole liiketoiminnallisesti merkitt\u00e4v\u00e4. Toki tietoalustan voi my\u00f6s kasata \"If you build it, they will come\"-periaatteella, jossa luotetaan siihen, ett\u00e4 mahdollisuus luo k\u00e4ytt\u00f6tarkoituksia.</p> <p>Teht\u00e4v\u00e4</p> <p>Keksi esimerkkej\u00e4 ratkaisuista, jotka olisi mahdollista rakentaa ja jotka aiheuttavat Wow-efektin, mutta joista ei kaikesta hienoudesta huolimatta ole mink\u00e4\u00e4n sortin hy\u00f6ty\u00e4.</p> <p>Pohjana voit k\u00e4ytt\u00e4\u00e4: \"Ammattikorkeakoulun sis\u00e4\u00e4nk\u00e4yntiin tuodaan Info-n\u00e4ytt\u00f6, jossa n\u00e4kyy xxxxxx. Siihen ker\u00e4t\u00e4\u00e4n automaattisesti dataa yyyyyy ja zzzzzzz.\"</p> <p>Teht\u00e4v\u00e4</p> <p>Tee yll\u00e4 oleva uusiksi, mutta yrit\u00e4 l\u00f6yt\u00e4\u00e4 oikea ongelma, ja ratkaisu siihen. Mit\u00e4 dataa k\u00e4yt\u00e4t? Kuinka se ker\u00e4t\u00e4\u00e4n?</p>"},{"location":"data_alustat/hyodyt/#osaamisen-kehittaminen","title":"Osaamisen kehitt\u00e4minen","text":"<p>Data-alustat ja niihin liittyv\u00e4 ekosysteemi kehittyy nopeasti. T\u00e4m\u00e4 tarkoittaa, ett\u00e4 osaamisen kehitt\u00e4minen on jatkuvaa, ja ty\u00f6ntekij\u00f6iden etsiminen \"5+ vuoden kokemuksella\" on naiivia. Aiemmassa kohdassa mainitun PoC:n voi hyvin toteuttaa muutamalla eri ty\u00f6kalulla, jotta tulee kokeiltua, mitk\u00e4 ty\u00f6kalut istuvat juuri t\u00e4h\u00e4n caseen parhaiten. On \u00e4\u00e4rimm\u00e4isen todenn\u00e4k\u00f6ist\u00e4, ett\u00e4 kukaan yrityksen ty\u00f6ntekij\u00f6ist\u00e4 (tai edes hakijoista) ei ole k\u00e4ytt\u00e4nyt kaikkia ty\u00f6kaluja - jos mit\u00e4\u00e4n. Iteratiivinen kehitys, jossa ty\u00f6kaluja, k\u00e4yt\u00e4nteit\u00e4, datakulttuuria, osaamista ja liiketoimintaa kehitet\u00e4\u00e4n yhdess\u00e4, on todenn\u00e4k\u00f6isesti paras tapa edet\u00e4. Osaamista ja jossain m\u00e4\u00e4rin valmiiksi koeponnistettuja ratkaisuita voi hankkia my\u00f6s konsulttitaloilta, mutta t\u00e4ss\u00e4kin tapauksessa pit\u00e4isi onnistua varmistamaan, ett\u00e4 oman talon datakulttuuri kehittyy.</p>"},{"location":"data_alustat/hyodyt/#kulttuurin-muutos","title":"Kulttuurin muutos","text":"<p>Datavetoisen p\u00e4\u00e4t\u00f6ksenteon kulttuurin luominen on pitk\u00e4j\u00e4nteist\u00e4 ty\u00f6t\u00e4. Kulttuurin muutos ei tapahdu yhdess\u00e4 y\u00f6ss\u00e4, eik\u00e4 se tapahdu, jos data-alustan k\u00e4ytt\u00f6\u00f6notto on pelkk\u00e4 IT-projekti. Dataan tottuminen vaatii samankaltaista muutosta kuin digitalisaatio joitakin vuosia sitten.</p> <p>Tip</p> <p>Mieti, kuinka onnistuneesti kivijalkakaupan digitalisaatioprojekti etenee, jos yrityksen johto tilaa IT-osastolta firmalle nettisivut. Verkkosivuilta l\u00f6ytyy kaupan yhteystiedot ja esitteen voi ladata Word-dokumenttina. Pohdi, miten t\u00e4m\u00e4 analogia istuu data-alustan k\u00e4ytt\u00f6\u00f6nottoon ja datakulttuurin synnytt\u00e4miseen.</p>"},{"location":"data_alustat/hyodyt/#datan-laatu","title":"Datan laatu","text":"<p>Ilman laadukasta dataa tietoalustan onnistumisen mahdollisuudet ovat todella heikot. Datan laatua ei voi my\u00f6sk\u00e4\u00e4n kokonaisuudessaan ulkoistaa data engineereille, jotka saattavat tiedon Bronze tai Silver tasolle. Osa vastuusta on dataa tuottavilla tiimeill\u00e4. Vastuu jakautuu my\u00f6s liiketoiminnan suuntaan: he m\u00e4\u00e4rittelev\u00e4t bisnestermist\u00f6n. Kaiken perustana pit\u00e4isi olla datastrategia, joka l\u00e4p\u00e4isee koko yrityksen toiminnan.</p> <p>Warning</p> <p>Universaalia, kaikki datan laadun ongelmat poistavaa, j\u00e4rjestelm\u00e4\u00e4 ei ole olemassa. Datan laatu ei siis hoidu sill\u00e4, ett\u00e4 \"ostaa kerralla hyv\u00e4n tietoalustan.\"</p> <p>Datan laatu on aina liiketoiminnan ja datan kontekstista riippuvaista. On t\u00e4ysin mahdollista, ett\u00e4 datan laatuun liittyv\u00e4n ongelman ratkaisemiseksi tarvitaan samaan neuvotteluun ei-tekninen liiketoiminnan edustaja, data engineer, substanssiosaaja (esim. tutkija) ja mikropalvelun lead developer.</p>"},{"location":"data_alustat/olap/","title":"OLAP vs OLTP","text":""},{"location":"data_alustat/olap/#perusteet","title":"Perusteet","text":"<p>Tietokannat voidaan jakaa kahteen luokkaan k\u00e4ytt\u00f6tarkoituksen mukaan: operatiivisiin kantoihin ja tietovarastoihin (eng. data warehouse). Operatiiviset transaktiokannat k\u00e4sittelev\u00e4t tilauksia, varauksia, ottoja ja muita tilamuutoksia p\u00e4\u00e4asiassa rivi errallaan. N\u00e4m\u00e4 tuotannon kannalta kriittiset kannat eiv\u00e4t tyypillisesti tallenna historiadataa vaan edustavat datan nykytilannetta. Tietovarastot toimivat hyvin p\u00e4invastaisesti: tietokannan haut k\u00e4sittelev\u00e4t useita tuhansia tai miljoonia rivej\u00e4 kerrallaan, ja haettu tieto edustaa esimerkiksi keskim\u00e4\u00e4r\u00e4ist\u00e4 varausm\u00e4\u00e4r\u00e4\u00e4 per tietty asiakassektori. N\u00e4ille tiedon k\u00e4sittelyn malleille on vakiintuneet lyhenteet: tietovarastok\u00e4ytt\u00f6\u00e4 vastaa lyhenne OLAP (Online Analytics Processing), ja operatiivisten kantojen k\u00e4ytt\u00f6\u00e4 OLTP (Online Transaction Processing). Mallien eroavaisuudet on esitelty alla olevassa taulukossa.</p> <p></p> <p>Kuvio 1: Eri applikaatioiden data virtaa usein eri kantoihin. Data saatetaan ker\u00e4tysti yhteen tietovarastoon, jotta analyytikko, ylin johto, tai joku muu yrityksen sis\u00e4inen taho voi sit\u00e4 tarkastella.</p> OLTP OLAP Toiminta-ajatus Tallentaa ja palauttaa tietueita yrityksen p\u00e4ivitt\u00e4isen toiminnan takaamiseksi. Tukee p\u00e4\u00e4t\u00f6ksentekoa ja mahdollistaa datan louhinnan ja analysoinnin. Tyypillinen haku Loppuk\u00e4ytt\u00e4j\u00e4 sovelluksen k\u00e4ytt\u00f6liittym\u00e4n kautta. Pieni m\u00e4\u00e4r\u00e4 rivej\u00e4, jotka l\u00f6ydet\u00e4\u00e4n prim\u00e4\u00e4riavaimella tai muulla indeksoidulla kent\u00e4ll\u00e4. Data-analyytikko SQL-kyselyll\u00e4. Usein aggregoitua dataa, jota on suodatettu tai ryhmitelty sarakearvojen mukaan. Tyypillinen kirjoitus Yksitt\u00e4iseen riviin kohdistuva  kirjoitus tai muutos. Suuri er\u00e4 rivej\u00e4 ajastetussa ETL-prosessissa. Kyselyn laajuus Yksitt\u00e4inen tietue eli rivi, joka haetaan sen id:t\u00e4 tai avainta vasten Useita tietueita tai niiden aggregaatti (esimerkiski keskiarvo). Viive Nano- tai millisekunteja. Sekunteja tai tunteja. <p>Erilaiset tiedon hakisen ja tallentamisen tarpeet vaikuttavat niin teknisiin ratkaisuihin kuin tiedon loogisen malliin.</p>"},{"location":"data_alustat/terminologia/","title":"Terminologia","text":"<p>Alla useita kurssin aikana k\u00e4ytettyj\u00e4 termej\u00e4 keskitetysti.</p>"},{"location":"data_alustat/terminologia/#acid","title":"ACID","text":"<p>Nelj\u00e4n tekij\u00e4n (atomisuus, eheys, eristyvyys ja pysyvyys) kokonaisuus. ACID-periaatteita noudattava kanta on ihanteellisessa maailmassa virheenkest\u00e4v\u00e4 jopa vikatilanteissa tai suorittaessa useita kilpailevia kirjoitusoperaatiota yht\u00e4 aikaa</p>"},{"location":"data_alustat/terminologia/#cdc","title":"CDC","text":"<p>Muutostiedon kaappaus (englanniksi change data capture). Prosessi, jossa tunnistetaan l\u00e4hdekannan muutokset joko l\u00e4hes reaaliaikaisesti tai ajastetusti.</p>"},{"location":"data_alustat/terminologia/#data-lakehouse","title":"Data Lakehouse","text":"<p>Arkkitehtuuri, joka yhdist\u00e4\u00e4 tietovaraston (eng. data warehouse) sek\u00e4 tietoaltaan (eng. data lake) toiminnallisuuksia</p>"},{"location":"data_alustat/terminologia/#delta-lake","title":"Delta Lake","text":"<p>Avoimen l\u00e4hdekoodin tiedontallennuksen kerros, joka lis\u00e4\u00e4 ACID-periaatteiden mukaisen toiminnallisuuden tiedostopohjaiseen tietoaltaaseen.</p>"},{"location":"data_alustat/terminologia/#elt","title":"ELT","text":"<p>Alemman akronyymin eli ETL:n mukaelma, jossa tiedon muokkaus ja tiedon lataus kohdekantaan suoritetaan k\u00e4\u00e4nteisess\u00e4 j\u00e4rjestyksess\u00e4. Tietomallia muokataan vasta m\u00e4\u00e4r\u00e4np\u00e4\u00e4ss\u00e4, joka voi olla esimerkiksi tietovarasto tai jokin moderni tietoalusta</p>"},{"location":"data_alustat/terminologia/#etl","title":"ETL","text":"<p>Prosessi, jossa tieto kaapataan l\u00e4hdekannasta (extract), muunnetaan  kohdekannan tietomallin mukaiseksi (transform) ja ladataan kohdekantaan (load), joka on tyypillisesti tietovarasto</p>"},{"location":"data_alustat/terminologia/#modern-data-stack","title":"Modern Data Stack","text":"<p>Modernin vastakohtana on legacy, jolla viitataan menneiden vuosikymmenien monoliittisiin tietoalustoihin. Modern Data Stack ei ole yksitt\u00e4isen palveluntarjoajan myym\u00e4 tietoalusta vaan kokoelma erilaisia ty\u00f6kaluja, joiden avulla dataa voidaan k\u00e4sitell\u00e4 ja analysoida. Tyypillisesti moderni data stack koostuu tietoaltaasta, tietovarastosta, tietovirrasta ja BI-ty\u00f6kalusta. Siihen kuuluu tyypillisesti my\u00f6s orkestrointity\u00f6kaluja, infraan hallitsemiseen liittyvi\u00e4 ty\u00f6kaluja sek\u00e4 datakatalogi. Moderni data stack on usein pilvipohjainen. Yksitt\u00e4iset komponentit ovat modulaarisia, joten niit\u00e4 voidaan p\u00e4ivitt\u00e4\u00e4 tarpeen mukaan. Sek\u00e4 pilvipohjaisuus ett\u00e4 modulaarisuus mahdollistavat skaalautuvuuden, joka on yksi modernin data stackin keskeisist\u00e4 ominaisuuksista.</p>"},{"location":"data_alustat/terminologia/#olap","title":"OLAP","text":"<p>Online Analytics Processing. Tietovarastojen tiedon hakemisen ja tallentamisen malli.</p>"},{"location":"data_alustat/terminologia/#oltp","title":"OLTP","text":"<p>Online Transaction Processing. Operatiivisten kantojen tiedon hakemisen ja tallentamisen malli.</p>"},{"location":"data_alustat/terminologia/#tietoallas","title":"Tietoallas","text":"<p>Suurten tietomassojen tallennukseen tarkoitettu arkkitehtuuri. Mahdollistaa strukturoimattoman tiedon tallennuksen ja k\u00e4sittelyn. Tallennuskapasiteetti on usein hajautettua ja tiedostopohjaista, mik\u00e4 mahdollistaa edullisen horisontaalisen skaalauksen. Englanniksi data lake.</p>"},{"location":"data_alustat/terminologia/#tietovarasto","title":"Tietovarasto","text":"<p>J\u00e4rjestelm\u00e4, johon tuodaan ETL tai ELT-prosessin avulla useista eri tietokannoista tietoa, jotta hajallaan olevaa dataa voidaan k\u00e4sitell\u00e4 ja analysoida keskitetysti. Englanniksi data warehouse</p>"},{"location":"kerrokset/ingestion/","title":"Ingestion","text":"<p>Tietol\u00e4hteit\u00e4 on monenlaisia. Huomaa, ett\u00e4 kaikkia n\u00e4it\u00e4 voidaan tuoda tietoalustaan ETL tai ELT -ty\u00f6nkulkua noudattaen. Kirjaimet edustavat sanoja Extract, Transform, Load. Tiivistetysti ETL:n ja ELT:n ero on siin\u00e4, ett\u00e4 ETL:ss\u00e4 dataa muokataan ennen tietovarastoon vienti\u00e4, kun taas ELT:ss\u00e4 dataa muokataan vasta tietovarastoon viennin j\u00e4lkeen.</p> <p>Nykyisin ELT on yleisempi l\u00e4hestymistapa. Syit\u00e4 t\u00e4lle on monia, kuten:</p> <ul> <li>ETL:n T on vaikea m\u00e4\u00e4ritell\u00e4 pysyv\u00e4sti. Jos T:n m\u00e4\u00e4ritelm\u00e4 muuttuu, data joudutaan hakemaan alusta alkaen uusiksi tietovarastoon.</li> <li>Raakadata itsess\u00e4\u00e4n voi olla hy\u00f6dyllist\u00e4 koneoppimisen n\u00e4k\u00f6kulmasta.</li> </ul> <p>Ajoittain t\u00f6rm\u00e4\u00e4 my\u00f6s termiin EtLT, jolla korostetaan sit\u00e4, ett\u00e4 Extractin ja Loadin v\u00e4lill\u00e4 pienimuotoista datan k\u00e4sittely\u00e4. Dataa ei siis v\u00e4ltt\u00e4m\u00e4tt\u00e4 muokata lopulliseen tietovaraston tarvitsemaa muotoon, mutta sit\u00e4 saatetaan k\u00e4sitell\u00e4 esimerkiksi anonymisoinnin tai pseudonymisoinnin vuoksi, surrogaattiavainten laskemiseksi, tai muiden syiden vuoksi. </p>"},{"location":"kerrokset/ingestion/#saas-vs-diy","title":"SaaS vs. DIY","text":"<p>Tietoalustan rakentamiseen on useita eri l\u00e4hestymistapoja. Yksi on rakentaa kaikki itse. Toinen on ostaa kaikki valmiina palveluna. Kolmas on yhdist\u00e4\u00e4 n\u00e4it\u00e4 kahta. Mik\u00e4li k\u00e4yt\u00e4t ELT-l\u00e4hestymistapaa, ingestion tool lataa tiedon joko Staging tai Bronze tasolle, riippuen miten olet halunnut m\u00e4\u00e4ritell\u00e4 sen. Tietoalustasi vastaa T-kirjaimen toteutuksesta eli eri tietol\u00e4hteiden tiedojen mallintamisesta ja yhdist\u00e4misest\u00e4. Huomaa, ett\u00e4 t\u00e4m\u00e4 on t\u00e4ysin modularisoitavissa. Sinulla voi olla rinnakkain useita eri ELT-ty\u00f6ty\u00f6kaluja, joista kukin vastaa jostakin/joistakin tietol\u00e4hteist\u00e4.</p> <p>Teht\u00e4v\u00e4</p> <p>Tutustu seuraaviin SaaS-palveluihin. Mit\u00e4 tietol\u00e4hteit\u00e4 ne tukevat?</p> <ul> <li>Fivetran</li> <li>Airbyte (Cloud)</li> <li>AWS AppFlow</li> <li>Microsoft Fabric Data Factory</li> <li>Confluent</li> </ul> <p>Yksitt\u00e4isiin ty\u00f6kaluihin tutustuminen on kuitenkin t\u00e4m\u00e4n kurssin skoopin ulkopuolella. Mik\u00e4li sinulla on oikea yrityksen case, kannattaa vertailuttaa useita eri tarjoajia. Valittuun tarjoajaan voi vaikuttaa my\u00f6s yrityksesi jo valmiiksi k\u00e4ytt\u00e4m\u00e4 hyperscaler (AWS, Azure, Google.)</p>"},{"location":"kerrokset/ingestion/#tietolahteet","title":"Tietol\u00e4hteet","text":"<p>Alla on k\u00e4siteltyn\u00e4 tyypillisi\u00e4 tietol\u00e4hteit\u00e4 alkaen tietokannoita ja p\u00e4\u00e4ttyen web-sivuihin, joista tieto ladataan web-scrapingin avulla.</p>"},{"location":"kerrokset/ingestion/#tietokannat","title":"Tietokannat","text":""},{"location":"kerrokset/ingestion/#sql-ja-nosql","title":"SQL ja noSQL","text":"<p>Eri SQL-kantojen (MySQL, MariaDB, Postgresql) ja noSQL-kantojen (MongoDB, Cassandra) dataa voi ladata eri strategioita hy\u00f6dynt\u00e4en. SQL-kannoista palautuu lista monikkoja (<code>list[tuple]</code>), kun taas noSQL-kannoista palautuu JSON string tai lista sanakirjoja (<code>list[dict]</code>). Koska ingestion huolehtii vain latauksesta, ja T eli Transform tehd\u00e4\u00e4n vasta my\u00f6hemmiss\u00e4 vaiheissa, SQL ja noSQL saavat hyvin samankaltaisen kohtelun t\u00e4ss\u00e4 vaiheessa: dumppaa data stagingiin ja murehdi my\u00f6hemmin.</p> <ul> <li>non-CDC: Full Load joka y\u00f6 (naiivi)</li> <li>CDC: Inkrementaalista kentt\u00e4\u00e4 hy\u00f6tynt\u00e4en</li> <li>CDC: Muutoshistorian lukeminen</li> </ul> <p>Teht\u00e4v\u00e4</p> <p>Lataukseen hy\u00f6dynnet\u00e4\u00e4n tietokannan ajuria (JDBC/OBDC), joka mahdollistaa tietokannan lukemisen Pythonilla. Tyypillisesti n\u00e4m\u00e4 voi asentaa <code>pip</code>:n avulla. Tutustu seuraaviin paketteihin pintapuoleisesti: <code>pymysql</code>, <code>psycopg2</code>.</p> <p>Tip</p> <p>Termi CDC tarkoittaa Change Data Capture. Sill\u00e4 tarkoitetaan lyhesti ottaen sit\u00e4, ett\u00e4 latausty\u00f6kalu tai -skripti pyrkii hakemaan sen, mik\u00e4 on uutta sitten edellisen haun. T\u00e4m\u00e4 onnistuu esimerkiksi timestamp-kent\u00e4n avulla, jolloin latausty\u00f6kalu tiet\u00e4\u00e4, ett\u00e4 seuraavalla kerralla pit\u00e4\u00e4 hakea kaikki rivit, joiden timestamp on suurempi kuin edellisell\u00e4 kerralla.</p>"},{"location":"kerrokset/ingestion/#timestamp-cdc","title":"Timestamp CDC","text":"<p>Aikakoodikentt\u00e4\u00e4n tai monotonisesti kasvavaan ID-kentt\u00e4\u00e4n perustuva inkrementaalinen lataus on \u00e4\u00e4rimm\u00e4isen yksinkertainen. Ensimm\u00e4isell\u00e4 latauskerralla haetaan aivan kaikki rivit. Jatkossa haetaan vain rivit, joissa inkrementaalinen kentt\u00e4 on suurempi kuin edellisell\u00e4 kerralla.</p> <p>Suuret <code>SELECT * FROM table</code>-tyyliset kyselyt ovat tietokantapalvelimelle muistin- tai kiintolevynk\u00e4yt\u00f6n kannalta eritt\u00e4in raskaita. Eth\u00e4n aja vastaavia kyselyit\u00e4 tuotantokantaa vasten. Kriittiset kannat on suositeltavaa replikoida erilliseen tietokantaan, josta lataus voidaan tehd\u00e4. Jos ELT-skriptin kuorma kaataa palvelimen tai t\u00e4ytt\u00e4\u00e4 sen levytilan, tuotanto ei k\u00e4rsi. T\u00e4m\u00e4 on kallista, mutta turvallisempaa kuin tuotantokannan kuormittaminen.</p> <p>\u00c4\u00e4rimm\u00e4isen naiivi latausskriptin alku voisi olla seuraavanlainen:</p> <pre><code># Import pymysql library\nimport pymysql\nfrom imaginery_library import write_as_parquet\n\n# Connect to the database\nconnection = pymysql.connect(host='localhost',\n                             user='user',\n                             password='password',\n                             db='database'\n)\n\nif FULL_LOAD:\n    query = \"SELECT * FROM table\"\nelif CDC:\n    query = f\"SELECT * FROM table WHERE timestamp &gt; {last_timestamp}\"\n\n# Execute the query and dump to staging\nwrite_as_csv(connection.execute(query).fetchall())\n</code></pre> <p>Warning</p> <p>Timestamppiin perustuva inkrementaalinen lataus ei toteuta tietokannan poistoja laisinkaan. T\u00e4m\u00e4 on potentiaalinen GDPR-rike. T\u00e4m\u00e4n takia on suositeltavaa lukea muutoshistoriaa, jolloin poistotkin saadaan mukaan.</p>"},{"location":"kerrokset/ingestion/#binary-log-cdc","title":"Binary Log CDC","text":"<p>Binary log on tietokantapalvelimen alunperin sis\u00e4iseen k\u00e4ytt\u00f6\u00f6n tarkoitettu lokitiedosto, joka sis\u00e4lt\u00e4\u00e4 kaikki tietokannan muutokset. Binary logia voi lukea my\u00f6s ulkopuolinen sovellus, jolloin se toimii CDC:n tavoin. Tietokannat k\u00e4ytt\u00e4v\u00e4t lokitiedostoa muun muassa homogeeniseen replikointii (esim. MySQL =&gt; MySQL) sek\u00e4 vikaantumistilanteiden varalle. Binary log pit\u00e4\u00e4 erikseen olla aktivoituna tietokannassa; se ei v\u00e4ltt\u00e4m\u00e4tt\u00e4 ole oletuksena p\u00e4\u00e4ll\u00e4. Lis\u00e4ksi binlogia ei s\u00e4ilytet\u00e4 ikuisesti, joten sinulla on n p\u00e4iv\u00e4\u00e4 replikoida muutokset ennen kuin ne katoavat. Itse muutokset sis\u00e4lt\u00e4v\u00e4t operaation tyypin (write, update, delete) sek\u00e4 rivin vanhan ja uuden tilan.</p> <p>Mik\u00e4li CDC:n haluaa toteuttaa muutoshistoriaan nojaten, voi olla j\u00e4rkevint\u00e4 unohtaa kotikutoinen Python-skripti, ja ottaa k\u00e4ytt\u00f6\u00f6n jokin kaupallinen palvelu tai avoimen l\u00e4hdekoodin ty\u00f6kalu (esim. Apache Kafka + Debezium tai Airbyte.)</p> <p>Jos kuitenkin haluat tutustua konseptiin Pythonin avulla, t\u00e4m\u00e4 onnistuu esimerkiksi <code>python-mysql-replication</code>-kirjastolla.</p> <pre><code>from pymysqlreplication import BinLogStreamReader\nfrom pymysqlreplication.row_event import WriteRowsEvent, UpdateRowsEvent, DeleteRowsEvent\n\n# Start from log_file position log_pos.\n# Examples: log_file='mysql-bin.000003', log_pos=4\n# Keep only events that affect rows. Ignore e.g. DDL events.\nstream = BinLogStreamReader(\n    connection_settings=mysql_settings,\n    log_file=log_file, \n    log_pos=log_pos, \n    resume_stream=True,\n    only_events=[\n        WriteRowsEvent, \n        UpdateRowsEvent, \n        DeleteRowsEvent\n    ]\n)\n\n# Process the binary log events\nfor binlog_event in stream:\n    # Process\n    pass\n\n# Close connection\nstream.close()\n</code></pre>"},{"location":"kerrokset/ingestion/#tiedostot","title":"Tiedostot","text":"<p>TODO: Tiedon j\u00e4sentyneisyyden tasot: Structured, Semi-structured, Unstructured.</p>"},{"location":"kerrokset/ingestion/#api","title":"API","text":"<p>TODO: REST, GraphQL</p>"},{"location":"kerrokset/ingestion/#iot","title":"IoT","text":"<p>TODO: MQTT</p>"},{"location":"kerrokset/ingestion/#streaming","title":"Streaming","text":"<p>TODO: Pub/sub</p>"},{"location":"kerrokset/ingestion/#web-pages","title":"Web pages","text":"<p>TODO: Scraping</p>"},{"location":"kerrokset/processor/","title":"Processor","text":"<p>Prosessointi on ETL/ELT-lyhenteess\u00e4 T-kirjain. Data luetaan jostain, prosessoidaan tavalla tai toisella, ja kirjoitetaan johonkin. K\u00e4site on sen verran ymp\u00e4ripy\u00f6re\u00e4, ett\u00e4 k\u00e4sitell\u00e4\u00e4n se kahden esimerkin avulla. Kummassakin esimerkiss\u00e4 oletaan, ett\u00e4 tieto-alusta perustuu Databricksiin, jolloin laskennasta vastaa Apache Spark.</p> <p>Tip</p> <p>Apache Spark on koodattu Scala-ohjelmointikielell\u00e4, mutta driver node tarjoaa Python API:n (kuten my\u00f6s SQL API:n). Suorituskyvyn kannalta on t\u00e4ysin sama, kirjoitetaanko koodi SQL:n\u00e4, Pythonina, Scalana vai R:n\u00e4.</p>"},{"location":"kerrokset/processor/#case-batch-process-1-tb","title":"Case: Batch process 1 TB","text":"<p>Data on AWS:n S3-bucketissa (<code>s3://stage-bucket/staging/taulu/partition=yyyy-mm-dd/*.parquet</code>). Luot batch- eli er\u00e4ajoon perustuvan prosessin, joka lukee datan stagingilta (Extract), prosessoi (Transform) sen tarvitulla tavalla, ja lataa (Load) sen m\u00e4\u00e4r\u00e4np\u00e4\u00e4h\u00e4n. Dataa k\u00e4sitell\u00e4\u00e4n leikisti noin 1000 gigatavua joka y\u00f6. Data kirjoitetaan Bronzelle. My\u00f6s Bronze koostuu Parquet-tiedostoista, jotka on tallennettu Delta Lake -kerroksen kera S3:een (<code>s3://medaljonki/tables/table=uuid-afasdf-afasf/</code>). </p> <p>Tip</p> <p>Huomaa, ett\u00e4 pronssitaulun polussa taulun tunne on UUID. T\u00e4m\u00e4 esimerkki mallintaa tilannetta, jossa tauluja hallinnoidaan Unity Catalogin avulla. K\u00e4ytt\u00e4j\u00e4 vastaa taulujen loogisesta osuudesta, Databricks huolehtii fyysisen materilisoinnin asiakkaan S3-buckettiin.</p> <p>Kokeilet ajaa vertailun vuoksi prosessin muutamalla eri klusterikoolla. Kaikissa driver on sama (esim. <code>c5d.2xlarge</code>), ja sen hinta j\u00e4tet\u00e4\u00e4n lyhyemm\u00e4n esimerkin toiveissa huomioitta (joka on noin 6 \u20ac/kk jos prosessi kest\u00e4\u00e4 tunnin). K\u00e4yt\u00e4t samaa Pythonilla kirjoitettua pyspark-koodia kaikissa klustereissa. Koodi on seuraavanlainen:</p> <pre><code>def fancy_process_thingy(df:DataFrame) -&gt; DataFrame:\n    # Some narrow transformations. No joins. No aggregations.\n    return df\n\ndf = spark.read.parquet(\"s3://stage-bucket/staging/taulu/partition=yyyy-mm-dd/*.parquet\")\ndf_out = fancy_process_thingy(df)\ndf_out.write.format(\"delta\").save(\"s3://medaljonki/tables/table=uuid-afasdf-afasf/\")\n</code></pre> <p>Tip</p> <p>Voit kokeilla hintalaskuria itse: Databricksin laskuri</p> <p>Alla mahdollinen hintataulukko:</p> Cluster executor_count executor_type Jobin kesto Hinta per kk A 4 c5d.9xlarge 55 min 88 B 8 c5d.4xlarge 60 min 87 C 16 c5d.2xlarge 60 min 87 D 32 c5d.xlarge 60 min 88 <p>Huomaat, ett\u00e4 t\u00e4ss\u00e4 tapauksessa on k\u00e4yt\u00e4nn\u00f6ss\u00e4 sama, teetk\u00f6 ty\u00f6n 4 isolla executorilla vai 32 pienell\u00e4. Mik\u00e4li sinulla olisi kiire, voisit tehd\u00e4 jobin esimerkiksi 16x <code>c5d.4xlarge</code>:lla, ja se kest\u00e4isi noin 30 minuuttia. T\u00e4m\u00e4 maksaisi yh\u00e4 samat 88 dollaria. Kone olisi toki tuplasti kalliimpi kuin B-klusterin kone, mutta se olisi my\u00f6s tuplasti nopeampi.</p> <p>Warning</p> <p>Huomaa, ett\u00e4 hintalaskuri ottaa huomioon vain Databricksin osuuden. Databricks luo koneet AWS:n palveluun, joten lopulta saat samasta tietokoneesta kaksi laskua: Databricksilt\u00e4 ja AWS:lt\u00e4 omansa. Kone c5d.4xlarge maksaa Databricksiss\u00e4 $0.09 per tunti. AWS laskuttaa koneesta $0.872 per tunti. Er\u00e4ajoissa on mahdollista k\u00e4ytt\u00e4\u00e4 niin sanottuja spot-hinnastoja (vrt. p\u00f6rssis\u00e4hk\u00f6), jolloin AWS:n osuus voi olla merkitt\u00e4v\u00e4sti pienempi. </p> <p>Kaikissa yll\u00e4 olevissa esimerkiss\u00e4 on oletettu, ett\u00e4 Databricksiss\u00e4 kone on y\u00f6ll\u00e4 ajastettu jobi (Job Compute) ja yrityksell\u00e4 on Premium-tilaus. Hinnat ovat lokakuulta 2023.</p> <p>Teht\u00e4v\u00e4</p> <p>c5d.xlarge on Intel Xeon (Cascade Lake) -pohjainen virtuaalikone, jossa on NVMe SSD. X-large kokoluokan koneessa on 4 vCPU:ta (corea) ja 4 Gigaa muistia. CPU:RAM suhde on siis 1:1. Kone .4xlarge on nelinkertaisesti suurempi (16 vCPU ja 16 GB muistia).</p> <p>Suurin mahdollinen c5d-virtuaalikone on .24xlarge, jossa on 96 prosessoria (96 / 24 == 4) ja 192 GB rammia. T\u00e4m\u00e4 on AWS:n palvelinkaapista yksi kokonainen kone; 24x:\u00e4\u00e4 pienemm\u00e4t koneet ovat siit\u00e4 virtuaalisesti lohkottuja osia.</p> <p>Tutustu c5d-instansseihin AWS:n dokumentaatiossa sek\u00e4 niiden hinnastoon Amazon EC2 On-Demand Pricing.</p>"},{"location":"kerrokset/processor/#case-aggregate-and-join-process-1-tb","title":"Case: Aggregate and join process 1 TB","text":"<p>My\u00f6hemmin prosessoit dataa Silverilt\u00e4 Goldille. Teet uuden testin. T\u00e4ll\u00e4 kertaa data on useissa eri tauluissa, jotka sinun tulee joinata, ja lis\u00e4ksi aggegoida dataa useiden eri sarakkeiden avulla. Silverill\u00e4 olisi luontevaa k\u00e4ytt\u00e4\u00e4 SQL-kielt\u00e4, mutta pysytt\u00e4ydyt\u00e4\u00e4n t\u00e4ss\u00e4 esimerkiss\u00e4 Pythonissa, jotta koodi pysyy mahdollisimman samanlaisena kuin edellisess\u00e4 esimerkiss\u00e4. Koodi on seuraavanlainen:</p> <pre><code>def fancy_process_thingy(a, b, c) -&gt; DataFrame:\n    # Some wide transformations. Many joins. Such aggregations. Wow.\n    return df\n\ndf_a = spark.read.format(\"delta\").load(\"s3://medaljonki/tables/table=uuid-afasdf-afasf/\")\ndf_b = spark.read.format(\"delta\").load(\"s3://medaljonki/tables/table=uuid-ff00b1-12a00/\")\ndf_c = spark.read.format(\"delta\").load(\"s3://medaljonki/tables/table=uuid-727ed1-12345/\")\n\ndf_out = do_your_thing(df_a, df_b, df_c)\n</code></pre> Cluster executor_count executor_type Jobin kesto Hinta per kk A 4 c5d.9xlarge 55 min 88 B 8 c5d.4xlarge 72 min 105 C 16 c5d.2xlarge 120 min 174 D 32 c5d.xlarge inf min N/A <p>Huomaat, ett\u00e4 t\u00e4ss\u00e4 tapauksessa ei ole laisinkaan sama, teetk\u00f6 ty\u00f6n 4 isolla executorilla vai 32 pienell\u00e4. Pienin kone ei suoriutunut ty\u00f6st\u00e4 laisinkaan; suuremmat executorit selviytyiv\u00e4t \"wide\"-tyylisist\u00e4 operaatioista tehokkaammin.</p>"},{"location":"kerrokset/processor/#todellisuuden-monimutkaisuus","title":"Todellisuuden monimutkaisuus","text":"<p>Todellisuudessa Apache Sparkin optimointi vaatii yll\u00e4tt\u00e4v\u00e4n monen seikan huomioon ottamista. Usein suurimmat optimoinnit syntyv\u00e4t hyvinkin yksinkertaisilla koodiin teht\u00e4vill\u00e4 ratkaisuilla. Isomman koneen ottaminen k\u00e4ytt\u00f6\u00f6n ei ole suinkaan ensimm\u00e4inen tapa korjata ongelmalliset jobit.</p> <p>Teht\u00e4v\u00e4</p> <p>T\u00e4m\u00e4 Databricksin video n\u00e4ytt\u00e4\u00e4 k\u00e4yt\u00e4nn\u00f6ss\u00e4, milt\u00e4 optimointiin tarjottu Spark UI sek\u00e4 pikkuhiljaa vanhaksi k\u00e4yd\u00e4 Ganglia n\u00e4ytt\u00e4v\u00e4t: Data Collab Lab: Notes from the perf lab with fish and job (54 min). Katso tai v\u00e4hint\u00e4\u00e4nkin silm\u00e4ile video l\u00e4pi.</p> <p>Kannattaa lukaista my\u00f6s Databricksin Best practices: Cluster configuration sek\u00e4 kilpailevan yrityksen Snowflaken Warehouse Considerations.</p>"},{"location":"kerrokset/serving/","title":"Serving","text":"<p>TODO</p>"},{"location":"kerrokset/storage/","title":"Storage","text":"<p>TODO</p>"},{"location":"kerrokset/storage/#acid","title":"ACID","text":"Kirjain Termi Kuvaus A Atomisuus Transaktiot suoritetaan atomisesti eli kokonaan tai ei ollenkaan.  Vian ilmaantuessa kirjoitusoperaatio peruutetaan. C Eheys Monimerkityksellinen ja siten ongelmallinen termi, joka viittaa muun muassa siihen, ovatko prim\u00e4\u00e4ri- ja viiteavaimet p\u00e4tev\u00e4ss\u00e4 tilassa, ja siihen, ett\u00e4 vastataanko kyselyihin aina tuoreimmalla datalla vai onko k\u00e4yt\u00f6ss\u00e4 eventual consistency -malli. I Eristyvyys Kirjoitusoperaatiot suoritetaan siten, ett\u00e4 ne tapahtuvat toisistaan erill\u00e4\u00e4n. Tyypillinen esimerkki on, ett\u00e4 kaksi eri applikaatiota yritt\u00e4v\u00e4t muokata saman sarakkeen arvoa samalla hetkell\u00e4. D Pysyvyys Onnistuneiden transaktioiden pysyvyys pyrit\u00e4\u00e4n s\u00e4ilytt\u00e4m\u00e4\u00e4n vikatilanteissa. <p>TODO: Esittele Delta Lake, Hudi, Iceberg, jotka mahdollista omalta osaltaan ACID:n object storageen.</p>"},{"location":"kerrokset/storage/#ihmisluettavat-vs-binaariset-tiedostot","title":"Ihmisluettavat vs. bin\u00e4\u00e4riset tiedostot","text":"<p>TODO: Esittele JSON Lines vs. Parquet tai ORC.</p>"},{"location":"kerrokset/storage/#row-vs-columnar","title":"Row vs Columnar","text":"<p>Esittele Parquet.</p>"},{"location":"tietomalli/kuutio/","title":"OLAP-kuutio","text":"<p>Tulet t\u00f6rm\u00e4\u00e4m\u00e4\u00e4n v\u00e4kisinkin k\u00e4sitteeseen OLAP-kuutio tai datakuutio. Tietokoneella tiedosto on pitk\u00e4 sarja tavuja, joten tallennustilasta et suinkaan tule l\u00f6yt\u00e4m\u00e4\u00e4n kolmiulotteista k\u00f6ntti\u00e4 bittej\u00e4 ja nollia. Helpoin tapa l\u00e4hesty\u00e4 t\u00e4t\u00e4 lienee esimerkki, joten siirryt\u00e4\u00e4n suoraan tauluun:</p>"},{"location":"tietomalli/kuutio/#kasiteltava-data","title":"\ud83d\udc27 K\u00e4sitelt\u00e4v\u00e4 data","text":"<p>K\u00e4sitell\u00e4\u00e4n kuvitteellista pingviinidataa. Data my\u00f6t\u00e4ilee <code>seaborn-data/penguing.csv</code>-tiedostoa, johon t\u00f6rm\u00e4\u00e4t mit\u00e4 todenn\u00e4k\u00f6isemmin jossain vaiheessa data-osaajan uraasi tutoriaaleissa. </p> <p>Jotta esimerkki pysyy helppona, pidet\u00e4\u00e4n vain kolme ulottuvuutta: species, island ja sex. Ainut k\u00e4ytett\u00e4v\u00e4 metriikka on count eli havaintojen m\u00e4\u00e4r\u00e4 kullekin yhdistelm\u00e4lle. Kentt\u00e4\u00e4 ei luonnollisesti l\u00f6ydy alkuper\u00e4isest\u00e4 taulusta vaan se aggregoidaan SQL-kyselyn yhteydess\u00e4. Taulun rakenne on siis seuraavanlainen:</p> species island sex body_mass_g Adelie Torgersen female 3730 Adelie Torgersen female 3200 Adelie Biscoe male 3850 Adelie Dream female 3150 Adelie Dream male 3700 Adelie Dream female 3050 Chinstrap Dream male 3800 Chinstrap Dream female 3150 Chinstrap Torgersen male 3700 Chinstrap Torgersen female 3050 Chinstrap Biscoe male 3750 Chinstrap Biscoe female 3100 Gentoo Biscoe male 5250 Gentoo Biscoe female 4800 Gentoo Dream male 5250 Gentoo Dream female 4850"},{"location":"tietomalli/kuutio/#helppo-metodi","title":"Helppo metodi","text":"<p>Monet tietokannat tukevat <code>GROUP BY CUBE</code>-koontia, joka mahdollistaa OLAP-kuution hyvinkin helposti. Alla koodi:</p> <pre><code>SELECT \n    species, \n    island, \n    sex, \n    COUNT() as penguins\nFROM penguins\nGROUP BY CUBE (species, island, sex);\n</code></pre> <p>Kysely tuottaa 44 rivi\u00e4 dataa, joten en aseta sit\u00e4 kerralla n\u00e4ytille. Sen sijaan k\u00e4yd\u00e4\u00e4n l\u00e4pi se, kuinka saman tuloksen voisi saavuttaa manuaalisesti kasaamalla.</p>"},{"location":"tietomalli/kuutio/#tyolas-metodi","title":"Ty\u00f6l\u00e4s metodi","text":"<p>OLAP-kuution voi kasata yhdist\u00e4m\u00e4ll\u00e4 p\u00e4\u00e4llek\u00e4in (<code>UNION ALL</code>) useat eri queryt, joista kukin tuottaa joidenkin ulottuvuuksien m\u00e4\u00e4r\u00e4n. Tarvitsemme yhteens\u00e4 8 queryt\u00e4, jotka tuottavat seuraavat yhdistelm\u00e4t:</p> <ul> <li>(<code>N/A</code>) - Grand total</li> <li>(<code>sex</code>) - Group by sex</li> <li>(<code>species</code>)</li> <li>(<code>island</code>)</li> <li>(<code>species</code>, <code>island</code>) - Group by species and island</li> <li>(<code>species</code>, <code>sex</code>)</li> <li>(<code>island</code>, <code>sex</code>)</li> <li>(<code>species</code>, <code>island</code>, <code>sex</code>) - Group by all three dimensions</li> </ul>"},{"location":"tietomalli/kuutio/#grand-total","title":"Grand Total","text":"<pre><code>SELECT NULL AS species, NULL AS island, NULL AS sex, COUNT(*) AS penguins\nFROM penguins;\n</code></pre> species island sex penguins 16 <p>Yhteens\u00e4 pingviinej\u00e4 on 16, joten t\u00e4m\u00e4 rivi on itsest\u00e4\u00e4nselvyys. Tyhj\u00e4 kentt\u00e4 tarkoittaa arvoa NULL.</p>"},{"location":"tietomalli/kuutio/#group-by-sex","title":"Group by sex","text":"<pre><code>SELECT NULL AS species, NULL AS island, sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY sex\n</code></pre> species island sex penguins male 7 female 9 <p>Yhteens\u00e4 pingiinej\u00e4 on yh\u00e4 16, luonnollisesti, mutta t\u00e4m\u00e4n dimension mukaan m\u00e4\u00e4r\u00e4 jakautuu 7 urokseen ja 9 naaraaseen.</p> <p>Kyselyt (<code>island</code>) ja (<code>species</code>) ovat hyvin samanlaiset. Korvaa <code>GROUP BY metriikka</code> ja aseta muut kent\u00e4t tilaan NULL.</p>"},{"location":"tietomalli/kuutio/#group-by-species-island","title":"Group by species-island","text":"<pre><code>SELECT species, island, NULL AS sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY species, island\n</code></pre> species island sex penguins Adelie Biscoe 1 Adelie Dream 3 Adelie Torgersen 2 Chinstrap Biscoe 2 Chinstrap Dream 2 Chinstrap Torgersen 2 Gentoo Biscoe 2 Gentoo Dream 2 <p>Pingviinej\u00e4 on viel\u00e4kin 16, mutta laji-saari -yhdistelm\u00e4ll\u00e4 niiden m\u00e4\u00e4r\u00e4t jakautuvat n\u00e4in.</p> <p>Kuten yll\u00e4, muut kahta ulottuvuutta ryhmitt\u00e4v\u00e4t kyselyt ovat t\u00e4ysin samanlaisia kuin t\u00e4m\u00e4. Vaihta <code>GROUP BY metriikka1, metriikka2</code> toiseksi ja korvaa kolmas metriikka arvolla <code>NULL</code>.</p>"},{"location":"tietomalli/kuutio/#valmis-query","title":"Valmis query","text":"<p>Lopulta sama toistetaan my\u00f6s kolmella ulottuvuudella, ja kaikki queryt yhdistet\u00e4\u00e4n p\u00e4\u00e4llek\u00e4in <code>UNION ALL</code>-komennolla. Koko kysely n\u00e4ytt\u00e4\u00e4 siis t\u00e4lt\u00e4:</p> <pre><code>-- Group by (species, island, sex)\nSELECT species, island, sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY species, island, sex\n\nUNION ALL\n\n-- Group by (species, island)\nSELECT species, island, NULL AS sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY species, island\n\nUNION ALL\n\n-- Group by (species, sex)\nSELECT species, NULL AS island, sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY species, sex\n\nUNION ALL\n\n-- Group by (island, sex)\nSELECT NULL AS species, island, sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY island, sex\n\nUNION ALL\n\n-- Group by (species)\nSELECT species, NULL AS island, NULL AS sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY species\n\nUNION ALL\n\n-- Group by (island)\nSELECT NULL AS species, island, NULL AS sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY island\n\nUNION ALL\n\n-- Group by (sex)\nSELECT NULL AS species, NULL AS island, sex, COUNT(*) AS penguins\nFROM penguins\nGROUP BY sex\n\nUNION ALL\n\n-- Grand total (no grouping columns)\nSELECT NULL AS species, NULL AS island, NULL AS sex, COUNT(*) AS penguins\nFROM penguins;\n</code></pre>"},{"location":"tietomalli/kuutio/#kuution-kysely","title":"Kuution kysely","text":"<p>Kysely tuottaa 43 rivi\u00e4 dataa, joten en aseta sit\u00e4 kerralla n\u00e4ytille. Sen sijaan kokeillaan, kuinka sit\u00e4 voi k\u00e4sin pl\u00e4r\u00e4t\u00e4. Huomaa, ett\u00e4 sarake <code>penguins</code> ei suinkaan ole metriika siten, ett\u00e4 sit\u00e4 voisi summata sokkona. Jos n\u00e4in tekee, meill\u00e4 on mukamas 128 pingviini\u00e4:</p>"},{"location":"tietomalli/kuutio/#grand-total_1","title":"\u26d4 Grand Total","text":"<pre><code>SELECT SUM(penguins) AS total_penguins FROM cube_penguins;\n</code></pre> total_penguins 128 <p>T\u00e4m\u00e4 on varsin luontevaa, koska meill\u00e4 on 8 eri ryhm\u00e4\u00e4, joissa kussakin on 16 pingviini\u00e4, ja <code>8 x 16 == 128</code>.</p>"},{"location":"tietomalli/kuutio/#grand-total-oikea-tapa","title":"\u2705 Grand Total (oikea tapa)","text":"<pre><code>SELECT penguins AS total_penguins\nFROM cube_penguins\nWHERE \n    species IS NULL AND\n    island IS NULL AND\n    sex IS NULL;\n</code></pre> total_penguins 16"},{"location":"tietomalli/kuutio/#tarkemmat-kyselyt","title":"Tarkemmat kyselyt","text":"<p>Jatkossa voimme tarkistaa m\u00e4\u00e4r\u00e4n mink\u00e4 tahansa dimensioiden yhdistelm\u00e4n mukaan siten, ett\u00e4 otamme halutut dimensiot mukaan, ja <code>WHERE</code>-lausekkeessa s\u00e4\u00e4d\u00e4mme niiden filtteri\u00e4 <code>IS</code> tai <code>IS NOT NULL</code>-lausekkeilla. Lienee helppo kuvitella, ett\u00e4 t\u00e4m\u00e4 voisi olla graafisessa k\u00e4ytt\u00f6liittym\u00e4ss\u00e4 laatikko, johon voi raahata haluamansa dimensiot.</p> <p>Alla kaksi esimerkki\u00e4 selvyyden vuoksi.</p>"},{"location":"tietomalli/kuutio/#by-species","title":"By (species)","text":"<pre><code>SELECT species, penguins AS total_penguins\nFROM cube_penguins\nWHERE \n    species IS NOT NULL AND -- huomaa NOT\n    island IS NULL AND\n    sex IS NULL;\n</code></pre> species total_penguins Adelie 6 Chinstrap 6 Gentoo 4"},{"location":"tietomalli/kuutio/#by-species-island","title":"By (species, island)","text":"<pre><code>SELECT species, island, penguins \nFROM cube_penguins\nWHERE \n    species IS NOT NULL AND -- huomaa NOT\n    island IS NOT NULL AND -- huomaa NOT\n    sex IS NULL;\n</code></pre> species island penguins Adelie Biscoe 1 Adelie Dream 3 Adelie Torgersen 2 Chinstrap Biscoe 2 Chinstrap Dream 2 Chinstrap Torgersen 2 Gentoo Biscoe 2 Gentoo Dream 2"},{"location":"tietomalli/kuutio/#onko-kuutio-pakollinen","title":"Onko kuutio pakollinen?","text":"<p>Huomaa, ett\u00e4 esimerkiksi <code>by (species, island)</code>-kyselyn olisi voinut suorittaa alkuper\u00e4iseen tauluun n\u00e4in:</p> <pre><code>SELECT species, island, COUNT(*) AS penguins\nFROM penguins\nGROUP BY species, island;\n</code></pre> <p>Kuutio ei siis mitenk\u00e4\u00e4n maagisesti tarjoa jotakin uutta 3-ulotteista slice'n'dice ominaisuutta, vaan yksinkertaisesti sis\u00e4lt\u00e4\u00e4 valmiiksi tauluun leivotut aggregaatit. T\u00e4m\u00e4 kevent\u00e4\u00e4 BI-ty\u00f6kalun laskentakuormaa kun valitsimia valitaan.</p>"},{"location":"tietomalli/kuutio/#lisatietoa","title":"Lis\u00e4tietoa","text":"<p>Jos kaipaat syvent\u00e4v\u00e4\u00e4 selityst\u00e4 OLAP-kuutioista, katso Stanfordin yliopiston Jennifer Widomin Introduction to Databases-soittolistan loppupuolen videot. Tunnistat ne <code>olap</code>-sanasta otsikossa.</p>"},{"location":"tietomalli/tietomalli/","title":"Tietomalli","text":"<p>Tietomallilla tarkoitetaan sit\u00e4, kuinka tieto on tallennettu tauluihin ja miten taulut liittyv\u00e4t toisiinsa. T\u00e4ss\u00e4 kurssimateriaalissa on jo esitelty kaksi tietomallia: One Big Table ja normalisoitui (1-3NF). Kertaa n\u00e4m\u00e4 Historia-osiossa.</p>"},{"location":"tietomalli/tietomalli/#tietokantojen-ja-tietovarastojen-tietomallit","title":"Tietokantojen ja tietovarastojen tietomallit","text":"<p>Operatiivisten tuotantokantojen tietomalli rakennetaan sovelluksen tarpeen mukaan, joten kahden eri tuotantokannan tietomallit voivat olla kesken\u00e4\u00e4n hyvinkin poikkeavia. Tyypillisin tietomalli on relaatiotietokanta, jossa data on tallennettu tauluihin ja tietokanta noudattaa v\u00e4hint\u00e4\u00e4n ensimm\u00e4isen asteen normaalimuotoa, mutta k\u00e4yt\u00f6ss\u00e4 on jatkuvasti eneneviss\u00e4 m\u00e4\u00e4rin muita tietokantatyyppej\u00e4, kuten dokumentti- tai graafitietokantoja. N\u00e4iden relaatiotietokannoista poikkeavien kantatyyppien yleisnimen\u00e4 on NoSQL. Er\u00e4\u00e4nlainen hybridi on kanta, joka on tavallinen relaatiokanta, mutta applikaation ymm\u00e4rt\u00e4m\u00e4 data upotetaan BLOB tai JSON -kentt\u00e4\u00e4n, jolloin skeema voi muuttua ajan yli, vaikka itse taulun skeema pysyisi samana.</p> <p>TODO: SQL-esimerkki viel\u00e4 kertauksen vuoksi</p> <p>TODO: noSQL-esimerkki</p> <p>Tietovarastojen tietomallien diversiteetti on sen sijaan huomattavasti kapeampi; tietovarastot noudattavat l\u00e4hes poikkeuksetta t\u00e4htiskeemaa ja mukailevat Kimballin dimensiomallia, ainakin ulommilla kerroksilla. Tietovarastojen tietomalli rakennetaan yrityksen prosessien ja tietovaraston k\u00e4ytt\u00e4jien tarpeiden mukaan. N\u00e4in ollen operatiivisten kantojen ja ietovarastojen tietomallit rakennetaan hyvin erilaisista l\u00e4ht\u00f6kohdista; kummassakin on sama informaatio, mutta eri tavoin j\u00e4rjesteltyn\u00e4.</p>"},{"location":"tietomalli/tietomalli/#normalisoitu-vai-ei","title":"Normalisoitu vai ei","text":"<p>Tietovarasto ei hy\u00f6dy normalisoinnista, ainakaan samoissa m\u00e4\u00e4rin kuin operatiivinen kanta, koska tietovaraston k\u00e4ytt\u00f6tarkoitus ei ole palvella sovellusta tai k\u00e4ytt\u00e4j\u00e4\u00e4 nopeilla rivikohtaisilla luku- ja kirjoitusoperaatioilla. Tietovarastoon tuotu data muokataan usein toisenlaiseen tietomalliin: t\u00e4htiskeemaan. On mainittavan arvoista, ett\u00e4 ennen t\u00e4htiskeemaa tietovarastossa voi olla esimerkiksi Data Vault 2.0 -tyylinen kerros, joka on jossain m\u00e4\u00e4rin hybridi normalisoidun ja t\u00e4htimallin v\u00e4lill\u00e4, ja sis\u00e4lt\u00e4\u00e4 muun muassa rivien historiatietoa.</p> <p>T\u00e4htiskeema koostuu fakta- ja dimensiotauluista. Faktataulut mallintavat yrityksen prosesseja. Faktataulu on nimelt\u00e4\u00e4n esimerkiksi <code>fact_sales</code>, jonka yksitt\u00e4inen rivi on myyntioperaatio tai kuittirivi sis\u00e4lt\u00e4en tuotteen senhetkisen hinnan ja alennushinnan. T\u00e4h\u00e4n liittyv\u00e4 dimensiotaulu on esimerkiksi <code>dim_product</code>, jonka  yksitt\u00e4inen rivi kuvastaa tuotetta, tai dim_customer, jonka yksitt\u00e4inen rivi kuvastaa asiakasta.  Yhteen faktatauluun liittyy monta dimensiota. N\u00e4in syntyy t\u00e4hti, jossa keski\u00f6ss\u00e4 on faktataulu, ja  t\u00e4hden sarakkeet ovat dimensiotauluja. T\u00e4htiskeema sis\u00e4lt\u00e4\u00e4 redundanttia, toistuvaa tietoa, joten taulut ovat fyysisesti (tavuina mitattuna) huomattavasti suurempia kuin mit\u00e4 niiden alkuper\u00e4iset tietol\u00e4hteet eli normalisoidut relaatiotaulut. Dimensiotaulut ovat usein my\u00f6s hyvin leveit\u00e4:  niiss\u00e4 voi kymmeni\u00e4 tai satoja sarakkeita. Denormalisoitu dimensiotaulu saa ja voi sis\u00e4lt\u00e4\u00e4 toisistaan riippuvia sarakkeita, kuten: syntym\u00e4p\u00e4iv\u00e4 ja ik\u00e4; pituus, leveys ja pinta-ala; p\u00e4iv\u00e4m\u00e4\u00e4r\u00e4 ja viikonp\u00e4iv\u00e4. Normalisoidussa kannassa n\u00e4m\u00e4 tietoparit n\u00e4ht\u00e4isiin redundantteina, koska niill\u00e4 on riippuvuus; yhden arvon voi laskea toisesta.</p>"},{"location":"tietomalli/tietomalli/#avaintyypit","title":"Avaintyypit","text":""},{"location":"tietomalli/tietomalli/#tekninen-nakokulma","title":"Tekninen n\u00e4k\u00f6kulma","text":"<p>P\u00e4\u00e4avain ja viiteavain ovat siin\u00e4 mieless\u00e4 teknisen tason avaimia, ett\u00e4 ne eiv\u00e4t v\u00e4ltt\u00e4m\u00e4tt\u00e4 ole liiketoimintal\u00e4ht\u00f6isi\u00e4. Niit\u00e4 tarvitaan relaatioiden luomiseen ja tietojen yhdist\u00e4miseen, mutta ne eiv\u00e4t v\u00e4ltt\u00e4m\u00e4tt\u00e4 kerro mit\u00e4\u00e4n liiketoiminnasta tai sen prosesseista. Teknisen tason avaimet ovat yleens\u00e4 yksinkertaisia ja helposti ymm\u00e4rrett\u00e4vi\u00e4, mutta ne eiv\u00e4t v\u00e4ltt\u00e4m\u00e4tt\u00e4 ole liiketoimintal\u00e4ht\u00f6isi\u00e4.</p> <p>Aavain voi koostua useammasta kuin yhdest\u00e4 attribuutista. T\u00e4ll\u00f6in puhutaan yhdistelm\u00e4avaimesta (composite key). </p>"},{"location":"tietomalli/tietomalli/#paaavain-primary-key","title":"P\u00e4\u00e4avain (primary key)","text":"<p>Kolme seuraavaa termi\u00e4 on hyv\u00e4 tuntea. Ne voi k\u00e4sitt\u00e4\u00e4 Venn-diagrammin tyyliin siten, ett\u00e4 ylempi termi on aina seuraavan kattok\u00e4site:</p> <ul> <li>Yliavain (superkey)</li> <li>Kandidaattiavain (candidate key)</li> <li>P\u00e4\u00e4avain (primary key)</li> </ul> <p>Yliavain on yksi tai useampi kentt\u00e4, jotka yksil\u00f6iv\u00e4t tietueen taulussa. Kandidaattiavain on minimaalinen avain, eli suppein yhdistelm\u00e4avain, joka yh\u00e4 yksil\u00f6i tietueen taulussa. Kandidaattiavaimista voidaan valita yksi avain, joka on taulun p\u00e4\u00e4avain (primary key). P\u00e4\u00e4avaimen arvoa ei saa muuttaa eik\u00e4 se saa sis\u00e4lt\u00e4\u00e4 tietoa, joka voi muuttua. P\u00e4\u00e4arvo ei my\u00f6sk\u00e4\u00e4n voi olla NULL. <sup>1</sup></p>"},{"location":"tietomalli/tietomalli/#viiteavain-foreign-key","title":"Viiteavain (foreign key)","text":"<p>Viiteavain (foreign key) on attribuutti tai attribuuttien joukko, joka viittaa toisen taulun p\u00e4\u00e4avaimeen. Viiteavain luo suhteen kahden taulun v\u00e4lille ja mahdollistaa tietojen yhdist\u00e4misen.</p>"},{"location":"tietomalli/tietomalli/#liiketoiminnan-nakokulma","title":"Liiketoiminnan n\u00e4k\u00f6kulma","text":"<p>P\u00e4\u00e4avain ja viiteavain ovat teknisen tason avaimia, kun taas liiketoimintal\u00e4ht\u00f6iset avaimet ovat liiketoimintal\u00e4ht\u00f6isi\u00e4. Taulun tasolla ne voivat olla yh\u00e4 samoja avaimia: prim\u00e4\u00e4riavain voi esimerkiksi olla sijaisavain tai luonnollinen avain. Jako on nimenomaan se, ett\u00e4 onko katsojan n\u00e4k\u00f6kulmasta avain luonnollinen vai ei.</p>"},{"location":"tietomalli/tietomalli/#sijaisavain-surrogate","title":"Sijaisavain (surrogate)","text":"<p>Sijaisavain on sellainen avain, jolla ei (alunperin) ole liiketoiminnallista tai reaalimaailman merkityst\u00e4. Tyypillisesti se on SQL-lausekkeella <code>AUTO_INCREMENT</code> tai <code>SERIAL</code> luotu kokonaisluku, joka on uniikki ja kasvaa automaattisesti aina kun tauluun lis\u00e4t\u00e4\u00e4n uusi rivi. Alla simppeli esimerkki</p> this_is_a_surrogate_key name age 1 John 25 2 Jane 30 3 Jack 35"},{"location":"tietomalli/tietomalli/#luonnollinen-natural-avain","title":"Luonnollinen (natural) avain","text":"<p>Luonnollinen avain on yksi tai useampi attribuutti, joka yksil\u00f6i tietueen taulussa ja jolla on liiketoiminnallinen merkitys.</p> <p>Luonnollisen avaimen (natural key) m\u00e4\u00e4ritelm\u00e4 riippuu hieman siit\u00e4, k\u00e4sitell\u00e4\u00e4nk\u00f6 tietoa l\u00e4hdej\u00e4rjestelm\u00e4n vai tietovaraston n\u00e4k\u00f6kulmasta Tiukan m\u00e4\u00e4ritelm\u00e4n mukaan luonnollinen avain esiintyy j\u00e4rjestelm\u00e4n ulkopuolella sin\u00e4ll\u00e4\u00e4n, ja sill\u00e4 on sis\u00e4\u00e4nrakennettu merkitys. Esimerkkej\u00e4 ovat henkil\u00f6tunnus, kirjan ISBN, digitaalisen l\u00e4hteen DOI, laitteen sarjanumero, s\u00e4hk\u00f6postiosoite tai kojelaudalta l\u00f6ytyv\u00e4 VIN. Jopa (firstname, surname, birthdate) -yhdistelm\u00e4avainta voidaan pit\u00e4\u00e4 luonnollisena avaimena, joskin riski on, ett\u00e4 se ei ole uniikki. <sup>2</sup> </p> <p>Tietovaraston n\u00e4k\u00f6kulmasta voidaan k\u00e4ytt\u00e4\u00e4 l\u00f6yhemp\u00e4\u00e4 m\u00e4\u00e4ritelm\u00e4\u00e4 siten, ett\u00e4 esimerkiksi autoinkrementin tai satunnaisuuden avulla luotu CustomerID voi olla tietovaraston silmin luonnollinen avain, vaikka se onkin keinotekoisesti luotu, ja l\u00e4hdej\u00e4rjestelm\u00e4n n\u00e4k\u00f6kulmasta aivan selke\u00e4 sijaisavain. Tietovaraston n\u00e4k\u00f6kulmasta sill\u00e4 on kuitenkin jo selke\u00e4 merkitys: se edustaa yksil\u00f6llisesti tunnistettavaa asiakasta tosimaailmassa eli siin\u00e4 j\u00e4rjestelm\u00e4ss\u00e4, mist\u00e4 tieto on haettu. K\u00e4ytt\u00e4j\u00e4 <code>123</code> on sama k\u00e4ytt\u00e4j\u00e4 <code>123</code> nyt ja aina. Jos tietoa haetaan useista j\u00e4rjestelmist\u00e4, t\u00e4ytyy kuitenkin huomioida, ett\u00e4 eri j\u00e4rjestelmiss\u00e4 voi olla p\u00e4\u00e4llek\u00e4isi\u00e4 ID-numeroita.</p> <p>Tietovarastossa voidaan luoda uusia surrogaattiavaimia jos sille on tarvetta. Yksi tarve on hash surrogate key, joka luodaan esimerkiksi silloin, jos l\u00e4hdetaulun prim\u00e4\u00e4riavain koostuu useista kentist\u00e4, ja tietovarasto hy\u00f6tyy yksitt\u00e4isest\u00e4 uniikista kent\u00e4st\u00e4 (esimerkiksi CDC-prosessissa). Se voidaan laskea my\u00f6s bisnesavaimesta Data Vault -mallinnuksen yhteydess\u00e4 (ks. alta).</p>"},{"location":"tietomalli/tietomalli/#bisnesavain","title":"Bisnesavain","text":"<p>Jos kahdesta eri j\u00e4rjestelm\u00e4st\u00e4 poimitut tietueet voidaan yhdist\u00e4\u00e4 valittujen attribuuttien avulla, voimme puhua business key -kentist\u00e4. T\u00e4ll\u00f6in kent\u00e4t ovat luonnollisesti luonnollisia avaimia. <sup>3</sup></p> <p>Esimerkki: System A:n k\u00e4ytt\u00e4j\u00e4 <code>123</code> ja System B:n k\u00e4ytt\u00e4j\u00e4 <code>0000325</code> ovat sama henkil\u00f6, jotka tunnistetaan kentill\u00e4: <code>(firstname, surname, birthdate)</code>. T\u00e4h\u00e4n termiin t\u00f6rm\u00e4\u00e4t Data Vault -mallinnuksessa ja Master Data Management -yhteyksiss\u00e4.</p> <p>Parempi ratkaisu on luonnollisesti keskitetty k\u00e4ytt\u00e4j\u00e4hallinta, SSO (single sign-on) tai jokin muu tapa, jolla k\u00e4ytt\u00e4j\u00e4t tunnistetaan ja hallitaan keskitetysti. T\u00e4ll\u00f6in k\u00e4ytt\u00e4j\u00e4t voivat k\u00e4ytt\u00e4\u00e4 useita j\u00e4rjestelmi\u00e4 yhdell\u00e4 ja samalla tunnuksella, ja k\u00e4ytt\u00e4j\u00e4tiedot ovat aina ajan tasalla, ilman ett\u00e4 niit\u00e4 tarvitsee synkronoida eri j\u00e4rjestelmien v\u00e4lill\u00e4. GDPR:n kannalta on ongelmallista, jos et tied\u00e4, keit\u00e4 sinun asiakkaasi ovat, tai jos p\u00e4\u00e4ttelet omatoimisesti, kuka asiakas on yhdistelem\u00e4ll\u00e4 useiden j\u00e4rjestelmien tietoja kertomatta asiakkaalle t\u00e4st\u00e4 prosessista.</p>"},{"location":"tietomalli/tietomalli/#yleisimmat-mallinnusmenetelmat","title":"Yleisimm\u00e4t mallinnusmenetelm\u00e4t","text":""},{"location":"tietomalli/tietomalli/#inmon","title":"Inmon","text":"<p>TODO: Selit\u00e4.</p>"},{"location":"tietomalli/tietomalli/#kimball","title":"Kimball","text":"<p>TODO: Selit\u00e4.</p>"},{"location":"tietomalli/tietomalli/#data-vault","title":"Data Vault","text":"<p>TODO: Selit\u00e4.</p> <ol> <li> <p>Hao, Q. % Tsikerdekis, M. Grokking Relational Database Design. Manning Publications. 2025.\u00a0\u21a9</p> </li> <li> <p>Olson, J. Data Quality. Morgan Kaufmann. 2003.\u00a0\u21a9</p> </li> <li> <p>Linstedt, D. &amp; Olschimke, M. Building a Scalable Data Warehouse with Data Vault 2.0. Morgan Kaufmann. 2015.\u00a0\u21a9</p> </li> </ol>"}]}